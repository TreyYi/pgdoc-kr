<!-- doc/src/sgml/mvcc.sgml -->

 <chapter id="mvcc">
  <title>동시성 제어</title>

  <indexterm>
   <primary>concurrency</primary>
  </indexterm>

  <para>
   여기서는 둘 이상의 세션이 같은 자료를 동시에 접근하려고 할 때, 
   <productname>PostgreSQL</productname> 데이터베이스 시스템은 
   어떻게 작동하는가에 대해서 다룬다.
   동시성 제어의 목적은 이런 상황에서 어떻게 자료의 정합성을 보장하면서, 
   가장 효율적으로 각 세션이 자료를 사용할 수 있는가이다.
   데이터베이스 응용프로그램 모든 개발자는 여기서 다루고 있는 내용을 
   잘 숙지 하고 있으면 좋을 것이다.
  </para>

  <sect1 id="mvcc-intro">
   <title>소개</title>

   <indexterm>
    <primary>Multiversion Concurrency Control</primary>
   </indexterm>

   <indexterm>
    <primary>다중 버전 동시성 제어</primary>
   </indexterm>

   <indexterm>
    <primary>MVCC</primary>
   </indexterm>

   <indexterm>
    <primary>Serializable Snapshot Isolation</primary>
   </indexterm>

   <indexterm>
    <primary>직렬화가 가능한 스냅숏 격리</primary>
   </indexterm>

   <indexterm>
    <primary>SSI</primary>
   </indexterm>

   <para>
    <productname>PostgreSQL</productname>은 여러 작업자가
    동시에 자료를 사용하기 위한 풍부한 개발자 도구 세트를 제공한다.
    내부적으로 자료 동시성 처리는 다중버전 모델(다중 버전 동시성 제어
    Multiversion Concurrency Control, <acronym>MVCC</acronym>)을 
    이용해서 관리된다.
    이 기법은 각각의 트랜잭션이 
    쿼리를 실행하는 시점 기준으로 자료를 스냅숏(
    이것을 하나의 <firstterm>데이터베이스 버전</>이라 함)으로 처리해서, 
    그 세션이 사용하는 기법이다. 이렇게 함으로 해서, 
    각각의 트랜잭션은 각각의 버전으로 자료를 처리하게 된다.
    이렇게 개별 버전 처리를 <firstterm>트랜잭션 격리 transaction
    isolation</firstterm>라 한다.
    이렇게 여러 버전으로 같은 자료가 변경 되는 경우, 
    자료 정합성을 구현하기 위해서는 자료에 접근에 대한 잠금 처리가
    필요한데, <acronym>MVCC</acronym> 기법으로 
    최소한의 잠금을 사용해서, 다중 사용자 환경에서도 좋은 
    성능을 낼 수 있도록 한다.
   </para>

   <para>
    <acronym>MVCC</acronym> 기법의 이점은 자료를 기록하는데
    잠금을 하지 않기 때문에, 한 세션에서 자료를 기록 하는 중에도
    다른 세션에서 자료를 읽는 수 있다는 점이다.
    <productname>PostgreSQL</productname>에서는 이 격리 작업의
    수준을 세션별로 조절할 수 있으며, 
    자료 정합성 측면에서 가장 격리 수준이 엄격한
    <firstterm>직렬화가 가능한 스냅숏 격리 Serializable
    Snapshot Isolation</firstterm> (<acronym>SSI</acronym>)
    수준까지 모두 지원한다.
   </para>

   <para>
    응용 프로그램 개발자가 자료 정합성을 보장하기 위해서
    직접 자료 잠금 기능을 구현할 필요 없이, 
    <productname>PostgreSQL</productname>에서는 
    이를 위해 테이블 단위, 혹은 로우 단위 잠금 기능을 제공한다.
    한편, <acronym>MVCC</acronym> 기법으로 이 부분을 처리하면,
    잠금 처리 방법보다 보다 좋은 성능을 보장한다.
    물론, 단일 트랜잭션에 종속되지 않는, 
    응용 프로그램 측에서 사용할 수 있는 잠금 기능도 
    필요에 따라 사용할 필요도 있을 것이다.
   </para>
  </sect1>

  <sect1 id="transaction-iso">
   <title>트랜잭션 격리</title>

   <indexterm>
    <primary>transaction isolation</primary>
   </indexterm>

   <indexterm>
    <primary>트랜잭션 격리</primary>
   </indexterm>

   <para>
    <acronym>SQL</acronym> 표준안에서는 네 종류의 
    트랜잭션 격리 수준을 정의하고 있다.  가장 엄격한 
    격리 수준은 직렬화가 가능한 스냅숏 격리인데,
    이것은 마치 여러 세션의 같은 트랜잭션 작업을
    한 줄로 세워 차례 대로 진행하는 것과 같은 결과를 보장한다.
    나머지 세 종류의 격리는 동시에 진행 되는 트랜잭션들 사이
    허용 되는 작업의 범위에 따라서 구분된다.
    표준안에서는 직렬화 가능한 트랜잭션 격리 수준은
    동시에 진행되는 트랜잭션 사이의 상호 관계가 전혀 없어야
    한다고 정의한다. (이것은 놀라운 이야기다 -- 
    실 세계에서는 당연히 동시에 여러 트랜잭션들이 발생할 것이고, 
    이것들이 어떻게 서로 상호 관계를 안 할 수 있을까?)
   </para>

   <para>
    표준안에서 소개하고 있는 각 수준별 이름과 상호 작용 범위는 다음과 같다:

    <variablelist>
     <varlistentry>
      <term>
       dirty read
       <indexterm><primary>dirty read</primary></indexterm>
      </term>
     <listitem>
      <para>
        한 트랜잭션은 다른 트랜잭션에 아직 커밋하지 않은 자료도 읽을 수 있다.
       </para>
      </listitem>
     </varlistentry>

     <varlistentry>
      <term>
       nonrepeatable read
       <indexterm><primary>nonrepeatable read</primary></indexterm>
      </term>
     <listitem>
      <para>
        한 트랜잭션은 다른 트랜잭션에서 커밋한 자료를 읽을 수 있다.
        (처음 어떤 자료를 읽고, 다시 읽으려고 하는데, 
        그 사이 다른 트랜잭션이 자료를 변경하고 커밋했다면, 
        다음 읽는 값이 커밋된 값으로 읽을 수 있다.) 
       </para>
      </listitem>
     </varlistentry>

     <varlistentry>
      <term>
       phantom read
       <indexterm><primary>phantom read</primary></indexterm>
      </term>
     <listitem>
      <para>
        위와 같은 상황에서 다른 트랜잭션에 의한 커밋된 자료가
        있다 하더라도, 항상 자신의 트랜잭션에서 조회 했던 그 자료값 그대로 
        보여준다.  
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </para>

   <para>
    <indexterm>
     <primary>트랜잭션 격리 수준</primary>
    </indexterm>
    4 단계 트랜잭션 격리 수준과 그에 따른 작동 방식에 대한 설명은 
    <xref linkend="mvcc-isolevel-table">에서 설명한다.
   </para>

    <table tocentry="1" id="mvcc-isolevel-table">
     <title>표준 <acronym>SQL</acronym> 트랜잭션 격리 수준</title>
     <tgroup cols="4">
      <thead>
       <row>
        <entry>
         격리 수준
        </entry>
        <entry>
         Dirty Read
        </entry>
        <entry>
         Nonrepeatable Read
        </entry>
        <entry>
         Phantom Read
        </entry>
       </row>
      </thead>
      <tbody>
       <row>
        <entry>
         Read uncommitted
        </entry>
        <entry>
         가능
        </entry>
        <entry>
         가능
        </entry>
        <entry>
         가능
        </entry>
       </row>

       <row>
        <entry>
         Read committed
        </entry>
        <entry>
         불가능
        </entry>
        <entry>
         가능
        </entry>
        <entry>
         가능
        </entry>
       </row>

       <row>
        <entry>
         Repeatable read
        </entry>
        <entry>
         불가능
        </entry>
        <entry>
         불가능
        </entry>
        <entry>
         가능
        </entry>
       </row>

       <row>
        <entry>
         Serializable
        </entry>
        <entry>
         불가능
        </entry>
        <entry>
         불가능
        </entry>
        <entry>
         불가능
        </entry>
       </row>
      </tbody>
     </tgroup>
    </table>

   <para>
    <productname>PostgreSQL</productname>에서는 위에서 설명한 
    네가지 표준 트랜잭션 격리 수준 가운데, 세가지만 지원한다.
    (구문 상으로는 Read Uncommitted 레벨을 사용할 수 있으나, 
    내부적으로 Read Committed로 처리 된다.)
    또한 <productname>PostgreSQL</productname>의
    Repeatable Read 수준에서는 phantom read가 불가능하다.
    그래서, 선택한 수준의 작동 방식이 의도 했던 것보다 
    엄격하게 작동할 수도 있을 것이다.  이런 정책에 대해서는 
    표준 SQL에서 허용한다: 표준 규약에서는 
    각 수준에서 발생하면 안되는 경우에 대해서만 
    언급하지, 꼭 이렇게 구현되어야 한다고 정의하고 있지는 않기
    때문이다.  <productname>PostgreSQL</>에서
    Read Uncommitted 수준을 지원할 수 없었던 이유는 
    다중 버전 동시성 제어를 구현하는 경우는 
    이 수준을 지원할 수 없기 때문이다.
    사용할 수 있는 각 수준의 자세한 설명은 아래 절에서 한다.
   </para>

   <para>
    트랜잭션 격리 수준을 지정하려면, 
    <xref linkend="sql-set-transaction"> 명령을 사용한다.
   </para>

   <important>
     <para>
       <productname>PostgreSQL</productname> 몇몇 자료형과 함수는 
       트랜잭션 내 특별한 형태로 읽기 특성을 제공한다.
       특히, 자동 증가 칼럼으로 사용하는 <type>serial</type>
       자료형과, 시퀀스 같은 객체는 롤백이 없으며, 
       자료 변경 즉시 다른 모든 세션에서도 그 변경된 값을
       볼 수 있다. <xref linkend="functions-sequence">,
       <xref linkend="datatype-serial"> 참조.
     </para>
   </important>

  <sect2 id="xact-read-committed">
   <title>커밋된 읽기 격리 수준</title>

   <indexterm>
    <primary>transaction isolation level</primary>
    <secondary>read committed</secondary>
   </indexterm>

   <indexterm>
    <primary>트랜잭션 격리 수준</primary>
    <secondary>커밋된 읽기</secondary>
   </indexterm>

   <indexterm>
    <primary>read committed</primary>
   </indexterm>

   <indexterm>
    <primary>커밋된 읽기</primary>
   </indexterm>

   <para>
    <firstterm>Read Committed</firstterm> 수준은 
    <productname>PostgreSQL</productname> 기본 격리 수준이다.
    이 격리 수준을 사용하면,
    <command>SELECT</command> 쿼리
    (<literal>FOR UPDATE/SHARE</> 절을 사용하지 않는)
    는 이것을 실행되기 전에 커밋된 자료를 보여 준다;
    It never sees either uncommitted
    data or changes committed during query execution by concurrent
    transactions.  In effect, a <command>SELECT</command> query sees
    a snapshot of the database as of the instant the query begins to
    run.   However, <command>SELECT</command> does see the effects
    of previous updates executed within its own transaction, even
    though they are not yet committed.  Also note that two successive
    <command>SELECT</command> commands can see different data, even
    though they are within a single transaction, if other transactions
    commit changes during execution of the first <command>SELECT</command>.
   </para>

   <para>
    <command>UPDATE</command>, <command>DELETE</command>, <command>SELECT
    FOR UPDATE</command>, and <command>SELECT FOR SHARE</command> commands
    behave the same as <command>SELECT</command>
    in terms of searching for target rows: they will only find target rows
    that were committed as of the command start time.  However, such a target
    row might have already been updated (or deleted or locked) by
    another concurrent transaction by the time it is found.  In this case, the
    would-be updater will wait for the first updating transaction to commit or
    roll back (if it is still in progress).  If the first updater rolls back,
    then its effects are negated and the second updater can proceed with
    updating the originally found row.  If the first updater commits, the
    second updater will ignore the row if the first updater deleted it,
    otherwise it will attempt to apply its operation to the updated version of
    the row.  The search condition of the command (the <literal>WHERE</> clause) is
    re-evaluated to see if the updated version of the row still matches the
    search condition.  If so, the second updater proceeds with its operation
    using the updated version of the row.  In the case of
    <command>SELECT FOR UPDATE</command> and <command>SELECT FOR
    SHARE</command>, this means it is the updated version of the row that is
    locked and returned to the client.
   </para>

   <para>
    Because of the above rule, it is possible for an updating command to see an
    inconsistent snapshot: it can see the effects of concurrent updating
    commands on the same rows it is trying to update, but it
    does not see effects of those commands on other rows in the database.
    This behavior makes Read Committed mode unsuitable for commands that
    involve complex search conditions; however, it is just right for simpler
    cases.  For example, consider updating bank balances with transactions
    like:

<screen>
BEGIN;
UPDATE accounts SET balance = balance + 100.00 WHERE acctnum = 12345;
UPDATE accounts SET balance = balance - 100.00 WHERE acctnum = 7534;
COMMIT;
</screen>

    If two such transactions concurrently try to change the balance of account
    12345, we clearly want the second transaction to start with the updated
    version of the account's row.  Because each command is affecting only a
    predetermined row, letting it see the updated version of the row does
    not create any troublesome inconsistency.
   </para>

   <para>
    More complex usage can produce undesirable results in Read Committed
    mode.  For example, consider a <command>DELETE</command> command
    operating on data that is being both added and removed from its
    restriction criteria by another command, e.g., assume
    <literal>website</literal> is a two-row table with
    <literal>website.hits</literal> equaling <literal>9</literal> and
    <literal>10</literal>:

<screen>
BEGIN;
UPDATE website SET hits = hits + 1;
-- run from another session:  DELETE FROM website WHERE hits = 10;
COMMIT;
</screen>

    The <command>DELETE</command> will have no effect even though
    there is a <literal>website.hits = 10</literal> row before and
    after the <command>UPDATE</command>. This occurs because the
    pre-update row value <literal>9</> is skipped, and when the
    <command>UPDATE</command> completes and <command>DELETE</command>
    obtains a lock, the new row value is no longer <literal>10</> but
    <literal>11</>, which no longer matches the criteria.
   </para>

   <para>
    Because Read Committed mode starts each command with a new snapshot
    that includes all transactions committed up to that instant,
    subsequent commands in the same transaction will see the effects
    of the committed concurrent transaction in any case.  The point
    at issue above is whether or not a <emphasis>single</> command
    sees an absolutely consistent view of the database.
   </para>

   <para>
    The partial transaction isolation provided by Read Committed mode
    is adequate for many applications, and this mode is fast and simple
    to use;  however, it is not sufficient for all cases.  Applications
    that do complex queries and updates might require a more rigorously
    consistent view of the database than Read Committed mode provides.
   </para>
  </sect2>

  <sect2 id="xact-repeatable-read">
   <title>반복 가능한 읽기 격리 수준</title>

   <indexterm>
    <primary>transaction isolation level</primary>
    <secondary>repeatable read</secondary>
   </indexterm>

   <indexterm>
    <primary>트랜잭션 격리 수준</primary>
    <secondary>반복 가능한 읽기</secondary>
   </indexterm>

   <indexterm>
    <primary>repeatable read</primary>
   </indexterm>

   <indexterm>
    <primary>반복 가능한 읽기</primary>
   </indexterm>

   <para>
    The <firstterm>Repeatable Read</firstterm> isolation level only sees
    data committed before the transaction began; it never sees either
    uncommitted data or changes committed during transaction execution
    by concurrent transactions.  (However, the query does see the
    effects of previous updates executed within its own transaction,
    even though they are not yet committed.)  This is a stronger
    guarantee than is required by the <acronym>SQL</acronym> standard
    for this isolation level, and prevents all of the phenomena described
    in <xref linkend="mvcc-isolevel-table">.  As mentioned above, this is
    specifically allowed by the standard, which only describes the
    <emphasis>minimum</emphasis> protections each isolation level must
    provide.
   </para>

   <para>
    This level is different from Read Committed in that a query in a
    repeatable read transaction sees a snapshot as of the start of the
    <emphasis>transaction</>, not as of the start
    of the current query within the transaction.  Thus, successive
    <command>SELECT</command> commands within a <emphasis>single</>
    transaction see the same data, i.e., they do not see changes made by
    other transactions that committed after their own transaction started.
   </para>

   <para>
    Applications using this level must be prepared to retry transactions
    due to serialization failures.
   </para>

   <para>
    <command>UPDATE</command>, <command>DELETE</command>, <command>SELECT
    FOR UPDATE</command>, and <command>SELECT FOR SHARE</command> commands
    behave the same as <command>SELECT</command>
    in terms of searching for target rows: they will only find target rows
    that were committed as of the transaction start time.  However, such a
    target row might have already been updated (or deleted or locked) by
    another concurrent transaction by the time it is found.  In this case, the
    repeatable read transaction will wait for the first updating transaction to commit or
    roll back (if it is still in progress).  If the first updater rolls back,
    then its effects are negated and the repeatable read transaction can proceed
    with updating the originally found row.  But if the first updater commits
    (and actually updated or deleted the row, not just locked it)
    then the repeatable read transaction will be rolled back with the message

<screen>
ERROR:  could not serialize access due to concurrent update
</screen>

    because a repeatable read transaction cannot modify or lock rows changed by
    other transactions after the repeatable read transaction began.
   </para>

   <para>
    When an application receives this error message, it should abort
    the current transaction and retry the whole transaction from
    the beginning.  The second time through, the transaction will see the
    previously-committed change as part of its initial view of the database,
    so there is no logical conflict in using the new version of the row
    as the starting point for the new transaction's update.
   </para>

   <para>
    Note that only updating transactions might need to be retried; read-only
    transactions will never have serialization conflicts.
   </para>

   <para>
    The Repeatable Read mode provides a rigorous guarantee that each
    transaction sees a completely stable view of the database.  However,
    this view will not necessarily always be consistent with some serial
    (one at a time) execution of concurrent transactions of the same level.
    For example, even a read only transaction at this level may see a
    control record updated to show that a batch has been completed but
    <emphasis>not</emphasis> see one of the detail records which is logically
    part of the batch because it read an earlier revision of the control
    record.  Attempts to enforce business rules by transactions running at
    this isolation level are not likely to work correctly without careful use
    of explicit locks to block conflicting transactions.
   </para>

   <note>
    <para>
     Prior to <productname>PostgreSQL</productname> version 9.1, a request
     for the Serializable transaction isolation level provided exactly the
     same behavior described here.  To retain the legacy Serializable
     behavior, Repeatable Read should now be requested.
    </para>
   </note>
  </sect2>

  <sect2 id="xact-serializable">
   <title>직렬화 가능한 격리 수준</title>

   <indexterm>
    <primary>transaction isolation level</primary>
    <secondary>serializable</secondary>
   </indexterm>

   <indexterm>
    <primary>트랜잭션 격리 수준</primary>
    <secondary>serializable</secondary>
   </indexterm>

   <indexterm>
    <primary>serializable</primary>
   </indexterm>

   <indexterm>
    <primary>predicate locking</primary>
   </indexterm>

   <indexterm>
    <primary>serialization anomaly</primary>
   </indexterm>

   <para>
    The <firstterm>Serializable</firstterm> isolation level provides
    the strictest transaction isolation.  This level emulates serial
    transaction execution for all committed transactions;
    as if transactions had been executed one after another, serially,
    rather than concurrently.  However, like the Repeatable Read level,
    applications using this level must
    be prepared to retry transactions due to serialization failures.
    In fact, this isolation level works exactly the same as Repeatable
    Read except that it monitors for conditions which could make
    execution of a concurrent set of serializable transactions behave
    in a manner inconsistent with all possible serial (one at a time)
    executions of those transactions.  This monitoring does not
    introduce any blocking beyond that present in repeatable read, but
    there is some overhead to the monitoring, and detection of the
    conditions which could cause a
    <firstterm>serialization anomaly</firstterm> will trigger a
    <firstterm>serialization failure</firstterm>.
   </para>

   <para>
    As an example,
    consider a table <structname>mytab</>, initially containing:
<screen>
 class | value
-------+-------
     1 |    10
     1 |    20
     2 |   100
     2 |   200
</screen>
    Suppose that serializable transaction A computes:
<screen>
SELECT SUM(value) FROM mytab WHERE class = 1;
</screen>
    and then inserts the result (30) as the <structfield>value</> in a
    new row with <structfield>class</><literal> = 2</>.  Concurrently, serializable
    transaction B computes:
<screen>
SELECT SUM(value) FROM mytab WHERE class = 2;
</screen>
    and obtains the result 300, which it inserts in a new row with
    <structfield>class</><literal> = 1</>.  Then both transactions try to commit.
    If either transaction were running at the Repeatable Read isolation level,
    both would be allowed to commit; but since there is no serial order of execution
    consistent with the result, using Serializable transactions will allow one
    transaction to commit and will roll the other back with this message:

<screen>
ERROR:  could not serialize access due to read/write dependencies among transactions
</screen>

    This is because if A had
    executed before B, B would have computed the sum 330, not 300, and
    similarly the other order would have resulted in a different sum
    computed by A.
   </para>

   <para>
    When relying on Serializable transactions to prevent anomalies, it is
    important that any data read from a permanent user table not be
    considered valid until the transaction which read it has successfully
    committed.  This is true even for read-only transactions, except that
    data read within a <firstterm>deferrable</firstterm> read-only
    transaction is known to be valid as soon as it is read, because such a
    transaction waits until it can acquire a snapshot guaranteed to be free
    from such problems before starting to read any data.  In all other cases
    applications must not depend on results read during a transaction that
    later aborted; instead, they should retry the transaction until it
    succeeds.
   </para>

   <para>
    To guarantee true serializability <productname>PostgreSQL</productname>
    uses <firstterm>predicate locking</>, which means that it keeps locks
    which allow it to determine when a write would have had an impact on
    the result of a previous read from a concurrent transaction, had it run
    first.  In <productname>PostgreSQL</productname> these locks do not
    cause any blocking and therefore can <emphasis>not</> play any part in
    causing a deadlock.  They are used to identify and flag dependencies
    among concurrent serializable transactions which in certain combinations
    can lead to serialization anomalies.  In contrast, a Read Committed or
    Repeatable Read transaction which wants to ensure data consistency may
    need to take out a lock on an entire table, which could block other
    users attempting to use that table, or it may use <literal>SELECT FOR
    UPDATE</literal> or <literal>SELECT FOR SHARE</literal> which not only
    can block other transactions but cause disk access.
   </para>

   <para>
    Predicate locks in <productname>PostgreSQL</productname>, like in most
    other database systems, are based on data actually accessed by a
    transaction.  These will show up in the
    <link linkend="view-pg-locks"><structname>pg_locks</structname></link>
    system view with a <literal>mode</> of <literal>SIReadLock</>.  The
    particular locks
    acquired during execution of a query will depend on the plan used by
    the query, and multiple finer-grained locks (e.g., tuple locks) may be
    combined into fewer coarser-grained locks (e.g., page locks) during the
    course of the transaction to prevent exhaustion of the memory used to
    track the locks.  A <literal>READ ONLY</> transaction may be able to
    release its SIRead locks before completion, if it detects that no
    conflicts can still occur which could lead to a serialization anomaly.
    In fact, <literal>READ ONLY</> transactions will often be able to
    establish that fact at startup and avoid taking any predicate locks.
    If you explicitly request a <literal>SERIALIZABLE READ ONLY DEFERRABLE</>
    transaction, it will block until it can establish this fact.  (This is
    the <emphasis>only</> case where Serializable transactions block but
    Repeatable Read transactions don't.)  On the other hand, SIRead locks
    often need to be kept past transaction commit, until overlapping read
    write transactions complete.
   </para>

   <para>
    Consistent use of Serializable transactions can simplify development.
    The guarantee that any set of concurrent serializable transactions will
    have the same effect as if they were run one at a time means that if
    you can demonstrate that a single transaction, as written, will do the
    right thing when run by itself, you can have confidence that it will
    do the right thing in any mix of serializable transactions, even without
    any information about what those other transactions might do.  It is
    important that an environment which uses this technique have a
    generalized way of handling serialization failures (which always return
    with a SQLSTATE value of '40001'), because it will be very hard to
    predict exactly which transactions might contribute to the read/write
    dependencies and need to be rolled back to prevent serialization
    anomalies.  The monitoring of read/write dependencies has a cost, as does
    the restart of transactions which are terminated with a serialization
    failure, but balanced against the cost and blocking involved in use of
    explicit locks and <literal>SELECT FOR UPDATE</> or <literal>SELECT FOR
    SHARE</>, Serializable transactions are the best performance choice
    for some environments.
   </para>

   <para>
    For optimal performance when relying on Serializable transactions for
    concurrency control, these issues should be considered:

    <itemizedlist>
     <listitem>
      <para>
       Declare transactions as <literal>READ ONLY</> when possible.
      </para>
     </listitem>
     <listitem>
      <para>
       Control the number of active connections, using a connection pool if
       needed.  This is always an important performance consideration, but
       it can be particularly important in a busy system using Serializable
       transactions.
      </para>
     </listitem>
     <listitem>
      <para>
       Don't put more into a single transaction than needed for integrity
       purposes.
      </para>
     </listitem>
     <listitem>
      <para>
       Don't leave connections dangling <quote>idle in transaction</quote>
       longer than necessary.
      </para>
     </listitem>
     <listitem>
      <para>
       Eliminate explicit locks, <literal>SELECT FOR UPDATE</>, and
       <literal>SELECT FOR SHARE</> where no longer needed due to the
       protections automatically provided by Serializable transactions.
      </para>
     </listitem>
     <listitem>
      <para>
       When the system is forced to combine multiple page-level predicate
       locks into a single relation-level predicate lock because the predicate
       lock table is short of memory, an increase in the rate of serialization
       failures may occur.  You can avoid this by increasing
       <xref linkend="guc-max-pred-locks-per-transaction">.
      </para>
     </listitem>
     <listitem>
      <para>
       A sequential scan will always necessitate a relation-level predicate
       lock.  This can result in an increased rate of serialization failures.
       It may be helpful to encourage the use of index scans by reducing
       <xref linkend="guc-random-page-cost"> and/or increasing
       <xref linkend="guc-cpu-tuple-cost">.  Be sure to weigh any decrease
       in transaction rollbacks and restarts against any overall change in
       query execution time.
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <warning>
    <para>
     Support for the Serializable transaction isolation level has not yet
     been added to Hot Standby replication targets (described in
     <xref linkend="hot-standby">).  The strictest isolation level currently
     supported in hot standby mode is Repeatable Read.  While performing all
     permanent database writes within Serializable transactions on the
     master will ensure that all standbys will eventually reach a consistent
     state, a Repeatable Read transaction run on the standby can sometimes
     see a transient state which is inconsistent with any serial execution
     of serializable transactions on the master.
    </para>
   </warning>
  </sect2>
 </sect1>

  <sect1 id="explicit-locking">
   <title>Explicit Locking</title>

   <indexterm>
    <primary>lock</primary>
   </indexterm>

   <para>
    <productname>PostgreSQL</productname> provides various lock modes
    to control concurrent access to data in tables.  These modes can
    be used for application-controlled locking in situations where
    <acronym>MVCC</acronym> does not give the desired behavior.  Also,
    most <productname>PostgreSQL</productname> commands automatically
    acquire locks of appropriate modes to ensure that referenced
    tables are not dropped or modified in incompatible ways while the
    command executes.  (For example, <command>TRUNCATE</> cannot safely be
    executed concurrently with other operations on the same table, so it
    obtains an exclusive lock on the table to enforce that.)
   </para>

   <para>
    To examine a list of the currently outstanding locks in a database
    server, use the
    <link linkend="view-pg-locks"><structname>pg_locks</structname></link>
    system view. For more information on monitoring the status of the lock
    manager subsystem, refer to <xref linkend="monitoring">.
   </para>

  <sect2 id="locking-tables">
   <title>Table-level Locks</title>

   <indexterm zone="locking-tables">
    <primary>LOCK</primary>
   </indexterm>

   <para>
    The list below shows the available lock modes and the contexts in
    which they are used automatically by
    <productname>PostgreSQL</productname>.  You can also acquire any
    of these locks explicitly with the command <xref
    linkend="sql-lock">.
    Remember that all of these lock modes are table-level locks,
    even if the name contains the word
    <quote>row</quote>; the names of the lock modes are historical.
    To some extent the names reflect the typical usage of each lock
    mode &mdash; but the semantics are all the same.  The only real difference
    between one lock mode and another is the set of lock modes with
    which each conflicts (see <xref linkend="table-lock-compatibility">).
    Two transactions cannot hold locks of conflicting
    modes on the same table at the same time.  (However, a transaction
    never conflicts with itself.  For example, it might acquire
    <literal>ACCESS EXCLUSIVE</literal> lock and later acquire
    <literal>ACCESS SHARE</literal> lock on the same table.)  Non-conflicting
    lock modes can be held concurrently by many transactions.  Notice in
    particular that some lock modes are self-conflicting (for example,
    an <literal>ACCESS EXCLUSIVE</literal> lock cannot be held by more than one
    transaction at a time) while others are not self-conflicting (for example,
    an <literal>ACCESS SHARE</literal> lock can be held by multiple transactions).
   </para>

     <variablelist>
      <title>Table-level Lock Modes</title>
      <varlistentry>
       <term>
        <literal>ACCESS SHARE</literal>
       </term>
       <listitem>
        <para>
         Conflicts with the <literal>ACCESS EXCLUSIVE</literal> lock
         mode only.
        </para>

        <para>
         The <command>SELECT</command> command acquires a lock of this mode on
         referenced tables.  In general, any query that only <emphasis>reads</> a table
         and does not modify it will acquire this lock mode.
        </para>
       </listitem>
      </varlistentry>

      <varlistentry>
       <term>
        <literal>ROW SHARE</literal>
       </term>
       <listitem>
        <para>
         Conflicts with the <literal>EXCLUSIVE</literal> and
         <literal>ACCESS EXCLUSIVE</literal> lock modes.
        </para>

        <para>
         The <command>SELECT FOR UPDATE</command> and
         <command>SELECT FOR SHARE</command> commands acquire a
         lock of this mode on the target table(s) (in addition to
         <literal>ACCESS SHARE</literal> locks on any other tables
         that are referenced but not selected
         <option>FOR UPDATE/FOR SHARE</option>).
        </para>
       </listitem>
      </varlistentry>

      <varlistentry>
       <term>
        <literal>ROW EXCLUSIVE</literal>
       </term>
       <listitem>
        <para>
         Conflicts with the <literal>SHARE</literal>, <literal>SHARE ROW
         EXCLUSIVE</literal>, <literal>EXCLUSIVE</literal>, and
         <literal>ACCESS EXCLUSIVE</literal> lock modes.
        </para>

        <para>
         The commands <command>UPDATE</command>,
         <command>DELETE</command>, and <command>INSERT</command>
         acquire this lock mode on the target table (in addition to
         <literal>ACCESS SHARE</literal> locks on any other referenced
         tables).  In general, this lock mode will be acquired by any
         command that <emphasis>modifies data</> in a table.
        </para>
       </listitem>
      </varlistentry>

      <varlistentry>
       <term>
        <literal>SHARE UPDATE EXCLUSIVE</literal>
       </term>
       <listitem>
        <para>
         Conflicts with the <literal>SHARE UPDATE EXCLUSIVE</literal>,
         <literal>SHARE</literal>, <literal>SHARE ROW
         EXCLUSIVE</literal>, <literal>EXCLUSIVE</literal>, and
         <literal>ACCESS EXCLUSIVE</literal> lock modes.
         This mode protects a table against
         concurrent schema changes and <command>VACUUM</> runs.
        </para>

        <para>
         Acquired by <command>VACUUM</command> (without <option>FULL</option>),
         <command>ANALYZE</>, <command>CREATE INDEX CONCURRENTLY</>, and
         some forms of <command>ALTER TABLE</command>.
        </para>
       </listitem>
      </varlistentry>

      <varlistentry>
       <term>
        <literal>SHARE</literal>
       </term>
       <listitem>
        <para>
         Conflicts with the <literal>ROW EXCLUSIVE</literal>,
         <literal>SHARE UPDATE EXCLUSIVE</literal>, <literal>SHARE ROW
         EXCLUSIVE</literal>, <literal>EXCLUSIVE</literal>, and
         <literal>ACCESS EXCLUSIVE</literal> lock modes.
         This mode protects a table against concurrent data changes.
        </para>

        <para>
         Acquired by <command>CREATE INDEX</command>
         (without <option>CONCURRENTLY</option>).
        </para>
       </listitem>
      </varlistentry>

      <varlistentry>
       <term>
        <literal>SHARE ROW EXCLUSIVE</literal>
       </term>
       <listitem>
        <para>
         Conflicts with the <literal>ROW EXCLUSIVE</literal>,
         <literal>SHARE UPDATE EXCLUSIVE</literal>,
         <literal>SHARE</literal>, <literal>SHARE ROW
         EXCLUSIVE</literal>, <literal>EXCLUSIVE</literal>, and
         <literal>ACCESS EXCLUSIVE</literal> lock modes.
         This mode protects a table against concurrent data changes, and
         is self-exclusive so that only one session can hold it at a time.
        </para>

        <para>
         This lock mode is not automatically acquired by any
         <productname>PostgreSQL</productname> command.
        </para>
       </listitem>
      </varlistentry>

      <varlistentry>
       <term>
        <literal>EXCLUSIVE</literal>
       </term>
       <listitem>
        <para>
         Conflicts with the <literal>ROW SHARE</literal>, <literal>ROW
         EXCLUSIVE</literal>, <literal>SHARE UPDATE
         EXCLUSIVE</literal>, <literal>SHARE</literal>, <literal>SHARE
         ROW EXCLUSIVE</literal>, <literal>EXCLUSIVE</literal>, and
         <literal>ACCESS EXCLUSIVE</literal> lock modes.
         This mode allows only concurrent <literal>ACCESS SHARE</literal> locks,
         i.e., only reads from the table can proceed in parallel with a
         transaction holding this lock mode.
        </para>

        <para>
         This lock mode is not automatically acquired on tables by any
         <productname>PostgreSQL</productname> command.
        </para>
       </listitem>
      </varlistentry>

      <varlistentry>
       <term>
        <literal>ACCESS EXCLUSIVE</literal>
       </term>
       <listitem>
        <para>
         Conflicts with locks of all modes (<literal>ACCESS
         SHARE</literal>, <literal>ROW SHARE</literal>, <literal>ROW
         EXCLUSIVE</literal>, <literal>SHARE UPDATE
         EXCLUSIVE</literal>, <literal>SHARE</literal>, <literal>SHARE
         ROW EXCLUSIVE</literal>, <literal>EXCLUSIVE</literal>, and
         <literal>ACCESS EXCLUSIVE</literal>).
         This mode guarantees that the
         holder is the only transaction accessing the table in any way.
        </para>

        <para>
         Acquired by the <command>ALTER TABLE</>, <command>DROP TABLE</>,
         <command>TRUNCATE</command>, <command>REINDEX</command>,
         <command>CLUSTER</command>, and <command>VACUUM FULL</command>
         commands.
         This is also the default lock mode for <command>LOCK TABLE</command>
         statements that do not specify a mode explicitly.
        </para>
       </listitem>
      </varlistentry>
     </variablelist>

     <tip>
      <para>
       Only an <literal>ACCESS EXCLUSIVE</literal> lock blocks a
       <command>SELECT</command> (without <option>FOR UPDATE/SHARE</option>)
       statement.
      </para>
     </tip>

   <para>
    Once acquired, a lock is normally held till end of transaction.  But if a
    lock is acquired after establishing a savepoint, the lock is released
    immediately if the savepoint is rolled back to.  This is consistent with
    the principle that <command>ROLLBACK</> cancels all effects of the
    commands since the savepoint.  The same holds for locks acquired within a
    <application>PL/pgSQL</> exception block: an error escape from the block
    releases locks acquired within it.
   </para>



    <table tocentry="1" id="table-lock-compatibility">
     <title> Conflicting Lock Modes</title>
     <tgroup cols="9">
      <colspec colnum="2" colname="lockst">
      <colspec colnum="9" colname="lockend">
      <spanspec namest="lockst" nameend="lockend" spanname="lockreq">
      <thead>
       <row>
        <entry morerows="1">Requested Lock Mode</entry>
        <entry spanname="lockreq">Current Lock Mode</entry>
       </row>
       <row>
        <entry>ACCESS SHARE</entry>
        <entry>ROW SHARE</entry>
        <entry>ROW EXCLUSIVE</entry>
        <entry>SHARE UPDATE EXCLUSIVE</entry>
        <entry>SHARE</entry>
        <entry>SHARE ROW EXCLUSIVE</entry>
        <entry>EXCLUSIVE</entry>
        <entry>ACCESS EXCLUSIVE</entry>
       </row>
      </thead>
      <tbody>
       <row>
        <entry>ACCESS SHARE</entry>
        <entry align="center"></entry>
        <entry align="center"></entry>
        <entry align="center"></entry>
        <entry align="center"></entry>
        <entry align="center"></entry>
        <entry align="center"></entry>
        <entry align="center"></entry>
        <entry align="center">X</entry>
       </row>
       <row>
        <entry>ROW SHARE</entry>
        <entry align="center"></entry>
        <entry align="center"></entry>
        <entry align="center"></entry>
        <entry align="center"></entry>
        <entry align="center"></entry>
        <entry align="center"></entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
       </row>
       <row>
        <entry>ROW EXCLUSIVE</entry>
        <entry align="center"></entry>
        <entry align="center"></entry>
        <entry align="center"></entry>
        <entry align="center"></entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
       </row>
       <row>
        <entry>SHARE UPDATE EXCLUSIVE</entry>
        <entry align="center"></entry>
        <entry align="center"></entry>
        <entry align="center"></entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
       </row>
       <row>
        <entry>SHARE</entry>
        <entry align="center"></entry>
        <entry align="center"></entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center"></entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
       </row>
       <row>
        <entry>SHARE ROW EXCLUSIVE</entry>
        <entry align="center"></entry>
        <entry align="center"></entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
       </row>
       <row>
        <entry>EXCLUSIVE</entry>
        <entry align="center"></entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
       </row>
       <row>
        <entry>ACCESS EXCLUSIVE</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
        <entry align="center">X</entry>
       </row>
      </tbody>
     </tgroup>
    </table>
   </sect2>

   <sect2 id="locking-rows">
    <title>Row-level Locks</title>

    <para>
     In addition to table-level locks, there are row-level locks, which
     can be exclusive or shared locks.  An exclusive row-level lock on a
     specific row is automatically acquired when the row is updated or
     deleted.  The lock is held until the transaction commits or rolls
     back, just like table-level locks.  Row-level locks do
     not affect data querying; they block only <emphasis>writers to the same
     row</emphasis>.
    </para>

    <para>
     To acquire an exclusive row-level lock on a row without actually
     modifying the row, select the row with <command>SELECT FOR
     UPDATE</command>.  Note that once the row-level lock is acquired,
     the transaction can update the row multiple times without
     fear of conflicts.
    </para>

    <para>
     To acquire a shared row-level lock on a row, select the row with
     <command>SELECT FOR SHARE</command>.  A shared lock does not prevent
     other transactions from acquiring the same shared lock.  However,
     no transaction is allowed to update, delete, or exclusively lock a
     row on which any other transaction holds a shared lock.  Any attempt
     to do so will block until the shared lock(s) have been released.
    </para>

    <para>
     <productname>PostgreSQL</productname> doesn't remember any
     information about modified rows in memory, so there is no limit on
     the number of rows locked at one time.  However, locking a row
     might cause a disk write, e.g., <command>SELECT FOR
     UPDATE</command> modifies selected rows to mark them locked, and so
     will result in disk writes.
    </para>

    <para>
     In addition to table and row locks, page-level share/exclusive locks are
     used to control read/write access to table pages in the shared buffer
     pool.  These locks are released immediately after a row is fetched or
     updated.  Application developers normally need not be concerned with
     page-level locks, but they are mentioned here for completeness.
    </para>

   </sect2>

   <sect2 id="locking-deadlocks">
    <title>Deadlocks</title>

    <indexterm zone="locking-deadlocks">
     <primary>deadlock</primary>
    </indexterm>

    <para>
     The use of explicit locking can increase the likelihood of
     <firstterm>deadlocks</>, wherein two (or more) transactions each
     hold locks that the other wants.  For example, if transaction 1
     acquires an exclusive lock on table A and then tries to acquire
     an exclusive lock on table B, while transaction 2 has already
     exclusive-locked table B and now wants an exclusive lock on table
     A, then neither one can proceed.
     <productname>PostgreSQL</productname> automatically detects
     deadlock situations and resolves them by aborting one of the
     transactions involved, allowing the other(s) to complete.
     (Exactly which transaction will be aborted is difficult to
     predict and should not be relied upon.)
    </para>

    <para>
     Note that deadlocks can also occur as the result of row-level
     locks (and thus, they can occur even if explicit locking is not
     used). Consider the case in which two concurrent
     transactions modify a table. The first transaction executes:

<screen>
UPDATE accounts SET balance = balance + 100.00 WHERE acctnum = 11111;
</screen>

     This acquires a row-level lock on the row with the specified
     account number. Then, the second transaction executes:

<screen>
UPDATE accounts SET balance = balance + 100.00 WHERE acctnum = 22222;
UPDATE accounts SET balance = balance - 100.00 WHERE acctnum = 11111;
</screen>

     The first <command>UPDATE</command> statement successfully
     acquires a row-level lock on the specified row, so it succeeds in
     updating that row. However, the second <command>UPDATE</command>
     statement finds that the row it is attempting to update has
     already been locked, so it waits for the transaction that
     acquired the lock to complete. Transaction two is now waiting on
     transaction one to complete before it continues execution. Now,
     transaction one executes:

<screen>
UPDATE accounts SET balance = balance - 100.00 WHERE acctnum = 22222;
</screen>

     Transaction one attempts to acquire a row-level lock on the
     specified row, but it cannot: transaction two already holds such
     a lock. So it waits for transaction two to complete. Thus,
     transaction one is blocked on transaction two, and transaction
     two is blocked on transaction one: a deadlock
     condition. <productname>PostgreSQL</productname> will detect this
     situation and abort one of the transactions.
    </para>

    <para>
     The best defense against deadlocks is generally to avoid them by
     being certain that all applications using a database acquire
     locks on multiple objects in a consistent order. In the example
     above, if both transactions
     had updated the rows in the same order, no deadlock would have
     occurred. One should also ensure that the first lock acquired on
     an object in a transaction is the most restrictive mode that will be
     needed for that object.  If it is not feasible to verify this in
     advance, then deadlocks can be handled on-the-fly by retrying
     transactions that abort due to deadlocks.
    </para>

    <para>
     So long as no deadlock situation is detected, a transaction seeking
     either a table-level or row-level lock will wait indefinitely for
     conflicting locks to be released.  This means it is a bad idea for
     applications to hold transactions open for long periods of time
     (e.g., while waiting for user input).
    </para>
   </sect2>

   <sect2 id="advisory-locks">
    <title>Advisory Locks</title>

    <indexterm zone="advisory-locks">
     <primary>advisory lock</primary>
    </indexterm>

    <indexterm zone="advisory-locks">
     <primary>lock</primary>
     <secondary>advisory</secondary>
    </indexterm>

    <para>
     <productname>PostgreSQL</productname> provides a means for
     creating locks that have application-defined meanings.  These are
     called <firstterm>advisory locks</>, because the system does not
     enforce their use &mdash; it is up to the application to use them
     correctly.  Advisory locks can be useful for locking strategies
     that are an awkward fit for the MVCC model.
     For example, a common use of advisory locks is to emulate pessimistic
     locking strategies typical of so called <quote>flat file</> data
     management systems.
     While a flag stored in a table could be used for the same purpose,
     advisory locks are faster, avoid table bloat, and are automatically
     cleaned up by the server at the end of the session.
    </para>

    <para>
     There are two ways to acquire an advisory lock in
     <productname>PostgreSQL</productname>: at session level or at
     transaction level.
     Once acquired at session level, an advisory lock is held until
     explicitly released or the session ends.  Unlike standard lock requests,
     session-level advisory lock requests do not honor transaction semantics:
     a lock acquired during a transaction that is later rolled back will still
     be held following the rollback, and likewise an unlock is effective even
     if the calling transaction fails later.  A lock can be acquired multiple
     times by its owning process; for each completed lock request there must
     be a corresponding unlock request before the lock is actually released.
     Transaction-level lock requests, on the other hand, behave more like
     regular lock requests: they are automatically released at the end of the
     transaction, and there is no explicit unlock operation.  This behavior
     is often more convenient than the session-level behavior for short-term
     usage of an advisory lock.
     Session-level and transaction-level lock requests for the same advisory
     lock identifier will block each other in the expected way.
     If a session already holds a given advisory lock, additional requests by
     it will always succeed, even if other sessions are awaiting the lock; this
     statement is true regardless of whether the existing lock hold and new
     request are at session level or transaction level.
    </para>

    <para>
     Like all locks in
     <productname>PostgreSQL</productname>, a complete list of advisory locks
     currently held by any session can be found in the <link
     linkend="view-pg-locks"><structname>pg_locks</structname></link> system
     view.
    </para>

    <para>
     Both advisory locks and regular locks are stored in a shared memory
     pool whose size is defined by the configuration variables
     <xref linkend="guc-max-locks-per-transaction"> and
     <xref linkend="guc-max-connections">.
     Care must be taken not to exhaust this
     memory or the server will be unable to grant any locks at all.
     This imposes an upper limit on the number of advisory locks
     grantable by the server, typically in the tens to hundreds of thousands
     depending on how the server is configured.
    </para>

    <para>
     In certain cases using advisory locking methods, especially in queries
     involving explicit ordering and <literal>LIMIT</> clauses, care must be
     taken to control the locks acquired because of the order in which SQL
     expressions are evaluated.  For example:
<screen>
SELECT pg_advisory_lock(id) FROM foo WHERE id = 12345; -- ok
SELECT pg_advisory_lock(id) FROM foo WHERE id &gt; 12345 LIMIT 100; -- danger!
SELECT pg_advisory_lock(q.id) FROM
(
  SELECT id FROM foo WHERE id &gt; 12345 LIMIT 100
) q; -- ok
</screen>
     In the above queries, the second form is dangerous because the
     <literal>LIMIT</> is not guaranteed to be applied before the locking
     function is executed.  This might cause some locks to be acquired
     that the application was not expecting, and hence would fail to release
     (until it ends the session).
     From the point of view of the application, such locks
     would be dangling, although still viewable in
     <structname>pg_locks</structname>.
    </para>

    <para>
     The functions provided to manipulate advisory locks are described in
     <xref linkend="functions-advisory-locks">.
    </para>
   </sect2>

  </sect1>

  <sect1 id="applevel-consistency">
   <title>Data Consistency Checks at the Application Level</title>

   <para>
    It is very difficult to enforce business rules regarding data integrity
    using Read Committed transactions because the view of the data is
    shifting with each statement, and even a single statement may not
    restrict itself to the statement's snapshot if a write conflict occurs.
   </para>

   <para>
    While a Repeatable Read transaction has a stable view of the data
    throughout its execution, there is a subtle issue with using
    <acronym>MVCC</acronym> snapshots for data consistency checks, involving
    something known as <firstterm>read/write conflicts</firstterm>.
    If one transaction writes data and a concurrent transaction attempts
    to read the same data (whether before or after the write), it cannot
    see the work of the other transaction.  The reader then appears to have
    executed first regardless of which started first or which committed
    first.  If that is as far as it goes, there is no problem, but
    if the reader also writes data which is read by a concurrent transaction
    there is now a transaction which appears to have run before either of
    the previously mentioned transactions.  If the transaction which appears
    to have executed last actually commits first, it is very easy for a
    cycle to appear in a graph of the order of execution of the transactions.
    When such a cycle appears, integrity checks will not work correctly
    without some help.
   </para>

   <para>
    As mentioned in <xref linkend="xact-serializable">, Serializable
    transactions are just Repeatable Read transactions which add
    nonblocking monitoring for dangerous patterns of read/write conflicts.
    When a pattern is detected which could cause a cycle in the apparent
    order of execution, one of the transactions involved is rolled back to
    break the cycle.
   </para>

   <sect2 id="serializable-consistency">
    <title>Enforcing Consistency With Serializable Transactions</title>

    <para>
     If the Serializable transaction isolation level is used for all writes
     and for all reads which need a consistent view of the data, no other
     effort is required to ensure consistency.  Software from other
     environments which is written to use serializable transactions to
     ensure consistency should <quote>just work</quote> in this regard in
     <productname>PostgreSQL</productname>.
    </para>

    <para>
     When using this technique, it will avoid creating an unnecessary burden
     for application programmers if the application software goes through a
     framework which automatically retries transactions which are rolled
     back with a serialization failure.  It may be a good idea to set
     <literal>default_transaction_isolation</> to <literal>serializable</>.
     It would also be wise to take some action to ensure that no other
     transaction isolation level is used, either inadvertently or to
     subvert integrity checks, through checks of the transaction isolation
     level in triggers.
    </para>

    <para>
     See <xref linkend="xact-serializable"> for performance suggestions.
    </para>

    <warning>
     <para>
      This level of integrity protection using Serializable transactions
      does not yet extend to hot standby mode (<xref linkend="hot-standby">).
      Because of that, those using hot standby may want to use Repeatable
      Read and explicit locking.on the master.
     </para>
    </warning>
   </sect2>

   <sect2 id="non-serializable-consistency">
    <title>Enforcing Consistency With Explicit Blocking Locks</title>

    <para>
     When non-serializable writes are possible,
     to ensure the current validity of a row and protect it against
     concurrent updates one must use <command>SELECT FOR UPDATE</command>,
     <command>SELECT FOR SHARE</command>, or an appropriate <command>LOCK
     TABLE</command> statement.  (<command>SELECT FOR UPDATE</command>
     and <command>SELECT FOR SHARE</command> lock just the
     returned rows against concurrent updates, while <command>LOCK
     TABLE</command> locks the whole table.)  This should be taken into
     account when porting applications to
     <productname>PostgreSQL</productname> from other environments.
    </para>

    <para>
     Also of note to those converting from other environments is the fact
     that <command>SELECT FOR UPDATE</command> does not ensure that a
     concurrent transaction will not update or delete a selected row.
     To do that in <productname>PostgreSQL</productname> you must actually
     update the row, even if no values need to be changed.
     <command>SELECT FOR UPDATE</command> <emphasis>temporarily blocks</emphasis>
     other transactions from acquiring the same lock or executing an
     <command>UPDATE</command> or <command>DELETE</command> which would
     affect the locked row, but once the transaction holding this lock
     commits or rolls back, a blocked transaction will proceed with the
     conflicting operation unless an actual <command>UPDATE</command> of
     the row was performed while the lock was held.
    </para>

    <para>
     Global validity checks require extra thought under
     non-serializable <acronym>MVCC</acronym>.
     For example, a banking application might wish to check that the sum of
     all credits in one table equals the sum of debits in another table,
     when both tables are being actively updated.  Comparing the results of two
     successive <literal>SELECT sum(...)</literal> commands will not work reliably in
     Read Committed mode, since the second query will likely include the results
     of transactions not counted by the first.  Doing the two sums in a
     single repeatable read transaction will give an accurate picture of only the
     effects of transactions that committed before the repeatable read transaction
     started &mdash; but one might legitimately wonder whether the answer is still
     relevant by the time it is delivered.  If the repeatable read transaction
     itself applied some changes before trying to make the consistency check,
     the usefulness of the check becomes even more debatable, since now it
     includes some but not all post-transaction-start changes.  In such cases
     a careful person might wish to lock all tables needed for the check,
     in order to get an indisputable picture of current reality.  A
     <literal>SHARE</> mode (or higher) lock guarantees that there are no
     uncommitted changes in the locked table, other than those of the current
     transaction.
    </para>

    <para>
     Note also that if one is relying on explicit locking to prevent concurrent
     changes, one should either use Read Committed mode, or in Repeatable Read
     mode be careful to obtain
     locks before performing queries.  A lock obtained by a
     repeatable read transaction guarantees that no other transactions modifying
     the table are still running, but if the snapshot seen by the
     transaction predates obtaining the lock, it might predate some now-committed
     changes in the table.  A repeatable read transaction's snapshot is actually
     frozen at the start of its first query or data-modification command
     (<literal>SELECT</>, <literal>INSERT</>,
     <literal>UPDATE</>, or <literal>DELETE</>), so
     it is possible to obtain locks explicitly before the snapshot is
     frozen.
    </para>
   </sect2>
  </sect1>

  <sect1 id="locking-indexes">
   <title>Locking and Indexes</title>

   <indexterm zone="locking-indexes">
    <primary>index</primary>
    <secondary>locks</secondary>
   </indexterm>

   <para>
    Though <productname>PostgreSQL</productname>
    provides nonblocking read/write access to table
    data, nonblocking read/write access is not currently offered for every
    index access method implemented
    in <productname>PostgreSQL</productname>.
    The various index types are handled as follows:

    <variablelist>
     <varlistentry>
      <term>
       B-tree, <acronym>GiST</acronym> and <acronym>SP-GiST</acronym> indexes
      </term>
      <listitem>
       <para>
        Short-term share/exclusive page-level locks are used for
        read/write access. Locks are released immediately after each
        index row is fetched or inserted.  These index types provide
        the highest concurrency without deadlock conditions.
       </para>
      </listitem>
     </varlistentry>

     <varlistentry>
      <term>
       Hash indexes
      </term>
      <listitem>
       <para>
        Share/exclusive hash-bucket-level locks are used for read/write
        access.  Locks are released after the whole bucket is processed.
        Bucket-level locks provide better concurrency than index-level
        ones, but deadlock is possible since the locks are held longer
        than one index operation.
       </para>
      </listitem>
     </varlistentry>

     <varlistentry>
      <term>
       <acronym>GIN</acronym> indexes
      </term>
      <listitem>
       <para>
        Short-term share/exclusive page-level locks are used for
        read/write access. Locks are released immediately after each
        index row is fetched or inserted. But note that insertion of a
        GIN-indexed value usually produces several index key insertions
        per row, so GIN might do substantial work for a single value's
        insertion.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </para>

   <para>
    Currently, B-tree indexes offer the best performance for concurrent
    applications; since they also have more features than hash
    indexes, they are the recommended index type for concurrent
    applications that need to index scalar data. When dealing with
    non-scalar data, B-trees are not useful, and GiST, SP-GiST or GIN
    indexes should be used instead.
   </para>
  </sect1>
 </chapter>
