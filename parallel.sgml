<!-- doc/src/sgml/parallel.sgml -->

 <chapter id="parallel-query">
  <title>병렬 쿼리</title>

  <indexterm zone="parallel-query">
   <primary>병렬 쿼리</primary>
  </indexterm>

  <para>
   <productname>PostgreSQL</>은 쿼리를 빠르게 처리하기 위해 여러
   CPU를 활용하는 실행 계획을 사용할 수 있다.  이 기능은 병렬 쿼리라고
   알려져 있다.  많은 쿼리는 병렬 처리의 이점을 누리기 어려운 이유는
   현재 구현의 제한이나 직렬 쿼리 계획보다 더 빠른 실행 계획이 없기
   때문이다.  그러나 병렬 쿼리의 속도향상에 종종 매우 중요하다.  병렬
   처리 시, 2배 혹은 4배 그 이상 빠르게 실행할 수 있다.  대량의 데이터
   중 몇몇 행만 반환할 경우 가장 큰 효과가 있다. 
  </para>

 <sect1 id="how-parallel-query-works">
  <title>병렬 쿼리 작동 원리</title>

   <para>
    옵티마이저가 특정 쿼리의 빠른 실행을 위해 병렬 처리를 할 때,
    아래와 같이 <firstterm>Gather node</firstterm>를 포함하여
    실행계획을 세운다:

<screen>
EXPLAIN SELECT * FROM pgbench_accounts WHERE filler LIKE '%x%';
                                     QUERY PLAN                                      
-------------------------------------------------------------------------------------
 Gather  (cost=1000.00..217018.43 rows=1 width=97)
   Workers Planned: 2
   ->  Parallel Seq Scan on pgbench_accounts  (cost=0.00..216018.33 rows=1 width=97)
         Filter: (filler ~~ '%x%'::text)
(4 rows)
</screen>
   </para>

   <para>
    위 실행 계획 경우, <literal>Gather</literal> 노드는 병렬로 실행되는
    계획에 정확히 하나의 하위 계획을 갖는다. <literal>Gather</literal> 노드가
    실행 계획 트리의 맨 위에 있는 경우 모든 쿼리는 병렬로 실행된다.  실행
    계획 트리에 어딘 가에 (<literal>Gather</literal> 노드가) 있다면, 일부
    쿼리만 병렬로 실행된다.  위의 예에서 하나의 테이블만을 접근하는 쿼리는
    <literal>Gather</literal> 노드 외에 하나의 실행 계획만 있다; 실행 계획
    노드는 <literal>Gather</literal> 노드의 하위 실행 계획으로 병렬로 실행 된다.
   </para>

   <para>
    <link linkend="using-explain">EXPLAN 명령 사용하기</>를 통해서, 플래너가
    선택한 작업자의 수를 확인할 수 있다. <literal>Gather</literal> 노드가
    쿼리를 실행할 때, 사용자 세션은
    <link linkend="bgworker">백그라운드 작업자 프로세스</link> 수와
    플래너가 선택한 작업자 수와 동일한 프로세스가 요청된다.  한
    번에 존재할 수 있는 백그라운드 작업자의 수는
    <xref linkend="guc-max-worker-processes"> 설정값에 의해 제한되므로,
    병렬 쿼리가 계획된 작업자보다 적거나 작업자 없이 실행될
    수 있다.  최적의 계획은 사용 가능한 작업자 수에 따라 달라질 수
    있으므로 쿼리 성능이 저하 될 수 있다. 이런 현상이 빈번한 경우
    <varname>max_worker_processes</> 설정값을 늘리면 더 많은 작업자가
    동시에 실행되거나 <xref linkend="guc-max-parallel-workers-per-gather">
    설정값을 줄여 플래너가 더 적은 수의 작업자를 요청할 수 있다. 
   </para>

   <para>
    모든 백그라운드 작업 프로세스는 <literal>Gather</> 노드의 일부로
    실행계획으로 병렬 쿼리를 실행한다.  리더는 또한 실행계획의 일부를
    실행하긴 하지만 추가적인 책임이 있다: 작업자가 생성한 모든 튜플을
    읽어야만 한다.  적은 수의 튜블에 의해 병렬처리 실행계획이 생성될 때,
    쿼리 속도를 빠르게 하기 위해 리더는 종종 추가적인 작업자처럼
    행동한다.  이와 반대로, 많은 수의 튜블을 처리하는 실행계획이 
    생성될 때 리더는 작업자에 의해 생성된 튜블을 읽고, 
    <literal>Gather</> 노드 레벨 이상의 실행계획에서 필요한 추가적인
    작업 처리한다. 이러한 경우, 리더는 실행계획의 병렬 처리 부분을
    거의 수행하지 않는다.
   </para>
 </sect1>

 <sect1 id="when-can-parallel-query-be-used">
  <title>병렬 쿼리가 가능한 경우</title>

  <para>
    어떤 상황에서도 쿼리 플래너가 병렬 쿼리 계획을 생성하지 못하게
    하는 몇 가지 설정이 있다.  모든 병렬 쿼리 계획을 생성하려면
    아래와 같이 설정을 해야 한다.
  </para>

  <itemizedlist>
    <listitem>
      <para>
        <xref linkend="guc-max-parallel-workers-per-gather"> 설정값은
        0보다 큰 수로 설정해야 한다.
        <varname>max_parallel_workers_per_gather</varname>에 설정한 수보다
        더 많은 작업자가 사용되는 것은 특수한 경우다. 
      </para>
    </listitem>

    <listitem>
      <para>
        <xref linkend="guc-dynamic-shared-memory-type"> 설정이
        지정되어야 한다. 병렬 쿼리는 프로세스 협력에 데이터를 전달하기
        위하여 동적 공유 메모리가 필요하다. 
      </para>
    </listitem>
  </itemizedlist>

  <para>
    또한 데이터베이스 서버는 단일 사용자 모드로 실행되어서는 안된다.  전체
    데이터베이스 시스템이 싱글 프로세스로 실행되기 때문에 백그라운드 작업자는
    사용할 수 없다.
  </para>

  <para>
    병렬 쿼리 계획을 생성 할 수 있는 일반적인 경우에도, 플래너는 다음 중
    하나라도 해당되면 병렬 쿼리 실행 계획을 생성하지 않는다:
  </para>

  <itemizedlist>
    <listitem>
      <para> 
        쿼리가 데이터베이스의 로우를 쓰거나 락을 발생할 경우.  최상위
        레벨이나 CTE 내 수정 작업이 포함된 쿼리는 병렬 실행 계획은
        세워지지 않는다.  이 제한은 개선 될 예정이다.
      </para>
    </listitem>

    <listitem>
      <para>
        쿼리가 실행 중에 중단될 수 있는 경우, 시스템은 (쿼리가) 부분 또는
        추가로 실행 가능할 수 있다고 생각하기 때문에 병렬 실행 계획이
        생성되지 않는다. 예를 들어,
        <link linkend="sql-declare">DECLARE CURSOR</link> 명령을 이용하여
        커서를 생성한 경우, PL/pgsql의 
        <literal>FOR x IN 쿼리 LOOP .. END LOOP</literal> 형식과 같은
        루프는 병렬 쿼리로 절대로 실행되지 않는다.  왜냐하면 병렬 쿼리
        시스템은 병렬 쿼리가 실행 중일 때, 루프 내의 코드가 안전하게
        실행되는 지 검증할 수 없기 때문이다.
      </para>
    </listitem>

    <listitem>
      <para>
        쿼리가 <literal>PARALLEL UNSAFE</literal> 설정된 함수를 사용할
        경우.  대부분의 시스템 함수는 <literal>PARALLEL SAFE</literal>이지만
        기본값으로 사용자 정의 함수는 <literal>PARALLEL UNSAFE</literal>
        설정으로 만들어진다.
        이 옵션에 대한 설명은 <xref linkend="parallel-safety">에서 다룬다.
      </para>
    </listitem>

    <listitem>
      <para>
        쿼리가 이미 다른 쿼리 내부에서 병렬처리로 실행될 경우.  예를
        들어, 병렬 쿼리에 의해 호출된 함수가 SQL 쿼리 자체에 실행되면,
        쿼리는 병렬 실행 계획을 결코 사용하지 않는다.  현재 구현에서
        제한되어 있는데, 하나의 쿼리가 많은 수의 프로세스를 사용할
        수 있기 때문에 이 제한은 계속 유지될 예정이다.
      </para>
    </listitem>

    <listitem>
      <para>
        트랜잭션 격리 수준이 serializable일 경우.  아직 구현하지 못했음.
      </para>
    </listitem>
  </itemizedlist>

  <para>
    병렬 쿼리 계획이 특정 쿼리에서 생성된 경우라도 여러 상황에 따라
    병렬로 쿼리가 실행되지 않는다.  이 경우 <literal>Gather</> 노드가 없는
    것처럼 리더는 <literal>Gather</> 노드 아래에 있는 실행 계획 부분을
    전체를 자체적으로 실행한다.  이런 경우는 다음 조건 중 하나가 충족
    될 경우 발생한다.
  </para>

  <itemizedlist>
    <listitem>
      <para> 
        No background workers can be obtained because of the limitation that
        the total number of background workers cannot exceed
        <xref linkend="guc-max-worker-processes">.
      </para>
    </listitem>

    <listitem>
      <para> 
        The client sends an Execute message with a non-zero fetch count.
        See the discussion of the
        <link linkend="protocol-flow-ext-query">extended query protocol</link>.
        Since <link linkend="libpq">libpq</link> currently provides no way to
        send such a message, this can only occur when using a client that
        does not rely on libpq.  If this is a frequent
        occurrence, it may be a good idea to set
        <xref linkend="guc-max-parallel-workers-per-gather"> in sessions
        where it is likely, so as to avoid generating query plans that may
        be suboptimal when run serially.
      </para>
    </listitem>

    <listitem>
      <para> 
        A prepared statement is executed using a <literal>CREATE TABLE .. AS
        EXECUTE ..</literal> statement.  This construct converts what otherwise
        would have been a read-only operation into a read-write operation,
        making it ineligible for parallel query.
      </para>
    </listitem>

    <listitem>
      <para> 
        The transaction isolation level is serializable.  This situation
        does not normally arise, because parallel query plans are not
        generated when the transaction isolation level is serializable.
        However, it can happen if the transaction isolation level is changed to
        serializable after the plan is generated and before it is executed.
      </para>
    </listitem>
  </itemizedlist>
 </sect1>

 <sect1 id="parallel-plans">
  <title>Parallel Plans</title>

  <para>
    Because each worker executes the parallel portion of the plan to
    completion, it is not possible to simply take an ordinary query plan
    and run it using multiple workers.  Each worker would produce a full
    copy of the output result set, so the query would not run any faster
    than normal but would produce incorrect results.  Instead, the parallel
    portion of the plan must be what is known internally to the query
    optimizer as a <firstterm>partial plan</>; that is, it must be constructed
    so that each process which executes the plan will generate only a
    subset of the output rows in such a way that each required output row
    is guaranteed to be generated by exactly one of the cooperating processes.
  </para>

 <sect2 id="parallel-scans">
  <title>Parallel Scans</title>

  <para>
    Currently, the only type of scan which has been modified to work with
    parallel query is a sequential scan.  Therefore, the driving table in
    a parallel plan will always be scanned using a
    <literal>Parallel Seq Scan</>.  The relation's blocks will be divided
    among the cooperating processes.  Blocks are handed out one at a
    time, so that access to the relation remains sequential.  Each process
    will visit every tuple on the page assigned to it before requesting a new
    page.
  </para>
 </sect2>

 <sect2 id="parallel-joins">
  <title>Parallel Joins</title>

  <para>
    The driving table may be joined to one or more other tables using nested
    loops or hash joins.  The outer side of the join may be any kind of
    non-parallel plan that is otherwise supported by the planner provided that
    it is safe to run within a parallel worker.  For example, it may be an
    index scan which looks up a value based on a column taken from the inner
    table. Each worker will execute the outer side of the plan in full, which
    is why merge joins are not supported here. The outer side of a merge join
    will often involve sorting the entire inner table; even if it involves an
    index, it is unlikely to be productive to have multiple processes each
    conduct a full index scan of the inner table.
  </para>
 </sect2>

 <sect2 id="parallel-aggregation">
  <title>Parallel Aggregation</title>
  <para>
    It is not possible to perform the aggregation portion of a query entirely
    in parallel.  For example, if a query involves selecting
    <literal>COUNT(*)</>, each worker could compute a total, but those totals
    would need to combined in order to produce a final answer.  If the query
    involved a <literal>GROUP BY</> clause, a separate total would need to
    be computed for each group.  Even though aggregation can't be done entirely
    in parallel, queries involving aggregation are often excellent candidates
    for parallel query, because they typically read many rows but return only
    a few rows to the client.  Queries that return many rows to the client
    are often limited by the speed at which the client can read the data,
    in which case parallel query cannot help very much.
  </para>

  <para>
    <productname>PostgreSQL</> supports parallel aggregation by aggregating
    twice.  First, each process participating in the parallel portion of the
    query performs an aggregation step, producing a partial result for each
    group of which that process is aware.  This is reflected in the plan as
    a <literal>PartialAggregate</> node.  Second, the partial results are
    transferred to the leader via the <literal>Gather</> node.  Finally, the
    leader re-aggregates the results across all workers in order to produce
    the final result.  This is reflected in the plan as a
    <literal>FinalizeAggregate</> node.
  </para>

  <para>
    Parallel aggregation is not supported in all situations.  Each aggregate
    must be <link linkend="parallel-safety">safe</> for parallelism and must
    have a combine function.  If the aggregate has a transition state of type
    <literal>internal</>, it must have serialization and deserialization
    functions.  See <xref linkend="sql-createaggregate"> for more details.
    Parallel aggregation is not supported for ordered set aggregates or when
    the query involves <literal>GROUPING SETS</>.  It can only be used when
    all joins involved in the query are also part of the parallel portion
    of the plan.
  </para>

 </sect2>

 <sect2 id="parallel-plan-tips">
  <title>Parallel Plan Tips</title>

  <para>
    If a query that is expected to do so does not produce a parallel plan,
    you can try reducing <xref linkend="guc-parallel-setup-cost"> or
    <xref linkend="guc-parallel-tuple-cost">.  Of course, this plan may turn
    out to be slower than the serial plan which the planner preferred, but
    this will not always be the case.  If you don't get a parallel
    plan even with very small values of these settings (e.g. after setting
    them both to zero), there may be some reason why the query planner is
    unable to generate a parallel plan for your query.  See
    <xref linkend="when-can-parallel-query-be-used"> and
    <xref linkend="parallel-safety"> for information on why this may be
    the case.
  </para>

  <para>
    When executing a parallel plan, you can use <literal>EXPLAIN (ANALYZE,
    VERBOSE)</literal> to display per-worker statistics for each plan node.
    This may be useful in determining whether the work is being evenly
    distributed between all plan nodes and more generally in understanding the
    performance characteristics of the plan.
  </para>

 </sect2>
 </sect1>

 <sect1 id="parallel-safety">
  <title>Parallel Safety</title>

  <para>
    The planner classifies operations involved in a query as either
    <firstterm>parallel safe</>, <firstterm>parallel restricted</>,
    or <firstterm>parallel unsafe</>.  A parallel safe operation is one which
    does not conflict with the use of parallel query.  A parallel restricted
    operation is one which cannot be performed in a parallel worker, but which
    can be performed in the leader while parallel query is in use.  Therefore,
    parallel restricted operations can never occur below a <literal>Gather</>
    node, but can occur elsewhere in a plan which contains a
    <literal>Gather</> node.  A parallel unsafe operation is one which cannot
    be performed while parallel query is in use, not even in the leader.
    When a query contains anything which is parallel unsafe, parallel query
    is completely disabled for that query.
  </para>

  <para>
    The following operations are always parallel restricted.
  </para>

  <itemizedlist>
    <listitem>
      <para>
        Scans of common table expressions (CTEs).
      </para>
    </listitem>

    <listitem>
      <para>
        Scans of temporary tables.
      </para>
    </listitem>

    <listitem>
      <para>
        Scans of foreign tables, unless the foreign data wrapper has
        an <literal>IsForeignScanParallelSafe</> API which indicates otherwise.
      </para>
    </listitem>

    <listitem>
      <para>
        Access to an <literal>InitPlan</> or <literal>SubPlan</>.
      </para>
    </listitem>
  </itemizedlist>

 <sect2 id="parallel-labeling">
  <title>Parallel Labeling for Functions and Aggregates</title>

  <para>
    The planner cannot automatically determine whether a user-defined
    function or aggregate is parallel safe, parallel restricted, or parallel
    unsafe, because this would require predicting every operation which the
    function could possibly perform.  In general, this is equivalent to the
    Halting Problem and therefore impossible.  Even for simple functions
    where it conceivably be done, we do not try, since this would be expensive
    and error-prone.  Instead, all user-defined functions are assumed to
    be parallel unsafe unless otherwise marked.  When using
    <xref linkend="sql-createfunction"> or
    <xref linkend="sql-alterfunction">, markings can be set by specifying
    <literal>PARALLEL SAFE</>, <literal>PARALLEL RESTRICTED</>, or
    <literal>PARALLEL UNSAFE</> as appropriate.  When using
    <xref linkend="sql-createaggregate">, the
    <literal>PARALLEL</> option can be specified with <literal>SAFE</>,
    <literal>RESTRICTED</>, or <literal>UNSAFE</> as the corresponding value.
  </para>

  <para>
    Functions and aggregates must be marked <literal>PARALLEL UNSAFE</> if
    they write to the database, access sequences, change the transaction state
    even temporarily (e.g. a PL/pgsql function which establishes an
    <literal>EXCEPTION</> block to catch errors), or make persistent changes to
    settings.  Similarly, functions must be marked <literal>PARALLEL
    RESTRICTED</> if they access temporary tables, client connection state,
    cursors, prepared statements, or miscellaneous backend-local state which
    the system cannot synchronize across workers. For example,
    <literal>setseed</> and <literal>random</> are parallel restricted for
    this last reason.
  </para>

  <para>
    In general, if a function is labeled as being safe when it is restricted or
    unsafe, or if it is labeled as being restricted when it is in fact unsafe,
    it may throw errors or produce wrong answers when used in a parallel query.
    C-language functions could in theory exhibit totally undefined behavior if
    mislabeled, since there is no way for the system to protect itself against
    arbitrary C code, but in most likely cases the result will be no worse than
    for any other function. If in doubt, it is probably best to label functions
    as <literal>UNSAFE</>.
  </para>

  <para>
    If a function executed within a parallel worker acquires locks which are
    not held by the leader, for example by querying a table not referenced in
    the query, those locks will be released at worker exit, not end of
    transaction. If you write a function which does this, and this behavior
    difference is important to you, mark such functions as
    <literal>PARALLEL RESTRICTED</literal>
    to ensure that they execute only in the leader. 
  </para>

  <para>
    Note that the query planner does not consider deferring the evaluation of
    parallel-restricted functions or aggregates involved in the query in
    order to obtain a superior plan.  So, for example, if a <literal>WHERE</>
    clause applied to a particular table is parallel restricted, the query
    planner will not consider placing the scan of that table below a 
    <literal>Gather</> node.  In some cases, it would be
    possible (and perhaps even efficient) to include the scan of that table in
    the parallel portion of the query and defer the evaluation of the
    <literal>WHERE</> clause so that it happens above the <literal>Gather</>
    node.  However, the planner does not do this.
  </para>

 </sect2>

 </sect1>

 </chapter>
