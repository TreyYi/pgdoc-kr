<!-- doc/src/sgml/high-availability.sgml -->

<chapter id="high-availability">
 <title>고가용성, 부하 분산, 복제</title>

 <indexterm><primary>high availability</></>
 <indexterm><primary>failover</></>
 <indexterm><primary>replication</></>
 <indexterm><primary>load balancing</></>
 <indexterm><primary>clustering</></>
 <indexterm><primary>data partitioning</></>
 <indexterm><primary>고가용성</></>
 <indexterm><primary>장애처리</></>
 <indexterm><primary>리플리케이션</></>
 <indexterm><primary>로드 밸런싱</></>
 <indexterm><primary>부하 분산</></>
 <indexterm><primary>클러스터링</></>
 <indexterm><primary>복제</></>


 <para>
  데이터베이스 서버는 하나의 운영 서버에서 장애가 생기면, 
  대기 서버가 빠르게 운영 서버로 운영될 수 있도록 구축할 수 있다.
  이것을 고가용성 high availability 이라고 한다.
  또한, 여러 대의 똑 같은 자료를 사용하는 서버를 동시에 운영해서, 
  서버 부하를 분산해서 운영할 수도 있다.
  이것을 부하 분산 load balancing 이라고 한다.
  단순하게 이상적으로만 생각한다면, 데이터베이스 서버도 별 문제점 없이 
  여러 대의 같은 서버가 운영될 수 있을 것이다.
  정적인 웹 페이지를 제공하는 웹 서버라면, 여러 대의 웹 서버를 구축해서, 
  여러 웹 블로우져 요청에 동시에 해당 페이지를 제공해서, 
  부하를 분산하는 작업은 그리 어려운 일이 아니다.
  하지만, 데이터베이스가 읽기 전용 형태로 서비스 되는 경우는 
  극히 드물다. 또한 하나의 요청에 내부적으로 자료를 읽고 쓰는 작업이 
  복잡하게 얽혀 있어, 쓰기 작업은 다른 서버에서 그 변경된 자료를 
  읽는 서비스까지 제공해야하기 때문에, 자료의 일관성 - 자료 정합성이라고 한다 - 을
  유지하는 작업이 꽤 난해한 작업이다.
 </para>

 <para>
  이 동기화 문제가 바로 병렬 데이터베이스 서버를 구축이 어려운 
  가장 근본적인 문제다. 이 문제를 해결 하는 서로 다른 여러 방법들이 
  있으며, 서로 다른 개선책을 제시하고 있다. 
 </para>

 <para>
  한 가지 해결책은 오직 하나의 데이터베이스만 읽기/쓰기를 허용하는 것이다.
  이 때, 이 서버를 <firstterm>마스터</> 또는 <firstterm>프라이머리</> 서버라고 한다.
  마스터 서버의 변경된 내용이 그대로 내부적으로 동기화 되는 서버를 
  <firstterm>스탠바이</> 또는 <firstterm>슬래이브</> 서버라고 한다. 
  마스터 서버의 장애로 운영 제어권을 스탠바이 서버로 남기기 전까지 
  스탠바이 서버를 사용할 없는 환경을 <firstterm>warm standby</> 서버 환경이라고 하고, 
  이와 달리 스탠바이 서버를 읽기 전용으로 사용이 가능한 환경을 
  <firstterm>hot standby</> 서버 환경이라고 한다.
  (일단은 용어들을 영어 단어 그대로 옮겼다. 운영 서버, 대기 서버, 주 서버, 보조 서버 등
  우리말 옮기고 싶었으나, 혼돈이 있을 것 같아, 그냥 그대로 옮겼다. 
  이 설명서 전체에 걸쳐 이렇게 명확히 구분해야하지 않을 상황이면, 
  운영 서버와 대기 서버를 사용한다.)
 </para>

 <para>
  다른 한 가지 해결책은 동기화 문제의 안전성을 보장하는 것이다. 
  데이터 변경 트랜잭션이 발생 했을 때, 사용하는 모든 서버에서
  그 트랜잭션이 커밋 되었을 때 만 그 트랜잭션을 유요한 트랜잭션으로 
  처리하는 방식이다. 이렇게 구현되면, 부하를 분산 할 수 있으며, 
  하나의 서버에서 장애가 발생되어도 자료의 정합성은 유지될 수 있다. 
  문제는 서버 자료 동기화 방식을 비동기식으로 처리한다면, 
  동기화 작업에 지연이 생긴 상황에서 한 서버에서 장애가 발생하면, 
  자료 손실이 있을 수 있다.
  비동기방식을 사용하는 경우는 서버간 통신이 아주 느린 경우에 사용한다.
 </para>

 <para>
  또 다른 한 가지 해결책은 자료 자체를 나눠서 동기화 하는 방법이다.
  데이터베이스 단위이거나, 테이블 단위로 해당 부분만 동기화한다.
 </para>

 <para>
  이런 여러 방식 가운데 어떤 방식을 선택할 것인가는 서버의 운영 특성과 
  자료 동기화 하는 방식의 성능에 따라 고려 해야한다.
  일반적으로 기능과 성능간의 상관관계를 가진다.
  예를 들어, 느린 네트워크 환경에서는 전체 동기화 방식을 사용한다면, 
  성능은 절반 이하로 떨어질 것이지만, 이런 경우에 비동기화 방식을 사용한다면, 
  서버 성능 저하를 최소화 할 수 있다.
 </para>

 <para>
  다음은 장애처리 failover, 복제 replication, 부하 분산 load balancing 
  기능을 제공하는 여러 기법을 대략적으로 소개하고 있다.
  각 용어들의 자세한 설명은 <ulink
    url="http://www.postgres-r.org/documentation/terms">용어설명</ulink>
        페이지를 참조하라.
 </para>

 <sect1 id="different-replication-solutions">
 <title>여러 해결 기법 비교</title>

 <variablelist>

  <varlistentry>
   <term>공유 디스크를 이용한 장애처리 failover</term>
   <listitem>

    <para>
         공유 디스크를 이용한 장애처리는 하나의 물리적인 데이터베이스 자료 파일만 
         사용하기 때문에, 자료 동기화에 대한 비용을 최소화 할 수 있다.
         하나의 디스크 영역을 여러 서버가 공유하는 방식이다. 
         운영 서버에 장애가 생기면, 대기 서버가 그 디스크 영역을 마운트 해서, 
         데이터베이스를 복구 모드로 실행한다. 이 방식은 자료 손실이 없이 
         빠르게 장애처리를 할 수 있다.
    </para>

    <para>
         이 방식은 일반적으로 네트워크 저장 장치와 같이 하드웨어 기능을 
         이용해서 공유하는 방식이다. 네트워크 파일 시스템을 이용할 수도 있으나, 
         그 파일 시스템이 <acronym>POSIX</> 모든 기능을 다 수용할 수 있어야한다.
         (자세한 이야기는 <xref
              linkend="creating-cluster-nfs"> 참조)
         이 방식의 한 가지 한계점은 운영서버가 그 디스크 영역을 쓰는 동안에는 
         대기서버가 전혀 그 디스크 영역을 사용할 수 없는 것이며, 
         만일 그 디스크 영역에 장애가 발생하면, 두 서버 모두 사용할 수 없다는 점이다.
    </para>

   </listitem>
  </varlistentry>

  <varlistentry>
   <term>파일 시스템 (블록-장치) 복제</term>
   <listitem>

    <para>
         하드웨어 기능을 이용한 또 다른 방식은 파일 시스템 자체를 복제하는 방식이다.
         데이터베이스가 운영되어 데이터 파일의 변경이 있었다면, 
         그 변경 내용에 대해서 다른 서버에도 파일 시스템 차원에서 동기화한다.
         제약 조건은 운영 서버의 변경 순서와 동일한 순서로 파일 시스템이 대기 서버에도 
         복제되어야한다. 이 방식을 이용한 리눅스 솔루션으로는 <productname>DRBD</>이다.
    </para>

<!--
https://forge.continuent.org/pipermail/sequoia/2006-November/004070.html

Oracle RAC is a shared disk approach and just send cache invalidations
to other nodes but not actual data. As the disk is shared, data is
only committed once to disk and there is a distributed locking
protocol to make nodes agree on a serializable transactional order.
-->

   </listitem>
  </varlistentry>

  <varlistentry>
   <term>트랜잭션 로그 전달</term>
   <listitem>

    <para>
        운영 서버의 미리 쓰는 로그(<acronym>WAL</>)의 내용을 
        대기 서버로 옮겨 그대로 다시 실행해서, 운영 서버 상태와 같은 상태를 
        유지하도록 하는 방법이다. 운영 서버가 장애로 중지되면, 
        즉시, 대기 서버가 운영 서버로 운영 될 수 있다.
        WAL 내용을 전달하는 방식은 동기식 또는 비동기식으로 이루워지며, 
        데이터베이스 서버 전체를 대상으로 한다. 부분만 복제할 수 없다.
    </para>

    <para>
         대기 서버를 구축하려면, WAL 내용을 대기 서버로 전달해야하 하는데, 
         그 전달하는 방법으로 파일 기반 로그 복사 (log shipping)를 하는 
         방식(<xref linkend="warm-standby">)과 스트리밍 리플리케이션(<xref linkend="streaming-replication">)
         방식, 이 두 방법을 혼용해서 사용할 수 있다. 
         hot standby 서버 구축에 대한 자세한 설명은 <xref linkend="hot-standby">
         에서 자세히 다루고 있다.
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
   <term>트리거 기반 운영-대기 복제</term>
   <listitem>

    <para>
         운영-대기 복제 환경의 기본 기능은 운영 서버에 일어난 
         자료 변경에 관계된 모든 쿼리를 대기 서버 쪽에도 
         똑같이 실행해서 운영 서버와 같은 환경을 만든다. 
         그리고, 대기 서버에서는 읽기 전용 쿼리만 허용해서, 
         자료 통계 작업 같은 할 수 있도록 이용한다.
    </para>

    <para>
         이 방식을 이용하는 제품으로는 <productname>Slony-I</>이 있다.
         테이블 단위 복제가 가능하며, 여러 대의 대기 서버를 함께 운영 할 수 있다.
         대기 서버의 자료 동기화 방식으로 비동기식이 사용됨으로, 장애 발생시 
         자료 손실이 있을 수 있다.
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
   <term>명령 구문 기반 복제 미들웨어</term>
   <listitem>

    <para>
         데이터베이스 서버로 보내는 모든 자료 변경 관련 쿼리를 미들웨어가 가로채서 관리되는 
         모든 데이터베이스 서버에 동시에 그 쿼리를 실행하는 방식이다.
         각각의 서버들은 서로 의존적이지 않게 운영될 수 있다. 읽기 전용 작업이라면, 
         그냥 한 서버 쪽으로만 작업하면 되고, 쓰기 작업이라면, 
         모든 서버로 보낸다. 물론 변경 작업 뒤 변경이 반경된 자료를 조회 하고자 한다면, 
         조회 하는 서버에 변경 작업 완료가 보장되어야한다.
    </para>

    <para>
         이 방식에서는  <function>random()</> 함수나, 
         <function>CURRENT_TIMESTAMP</>, 시퀀스 값과 같이
         개별 서버 의존적인 쿼리들에 대해서는
         의도되게 않게 일관성을 유지하지 못 할 수 있다.
         이런 쿼리 들이 자료 변경 작업에 사용된다면, 
         전혀 엉뚱한 결과가 나올 수도 있다.
         이런 문제에 대한 해결책을 미들웨어가 제시하지 못한다면, 
         응용 프로그램에서 이런 문제의 해결책을 반드시 찾고, 사용해야한다.
         한 방법은 한 서버에 먼저 자료를 반영해서, 반영 결과를 가지고, 
         다른 서버에 모두 반영하는 방법이 있겠고, 
         다른 방법으로 자료 변경에 대해서는 특정 시점 복구 방식을 이용한 
         운영-대기 서버 형태로 구축해서 자료 변경은 반드시 운영서버에서만 
         일어나도록 미들웨어나 응용프로그램 사용하는 것이다. 또 한 가지 주의할 
         사항은 한 서버에서 트랜잭션이 시작되어 커밋되었다면, 
         다른 모든 서버에서도 모두 커밋되어야 그 트랜잭션이 유효하다고 
         처리되어야한다. 특정 서버에서 롤백된다면, 그 트랜잭션은 모든 서버에서 
         롤백되어야한다. 이것을 구현하기 위해서는 미들웨어가 2중 커밋 two-phase commit
         을 이용할 것이다 (<xref linkend="sql-prepare-transaction">, 
         <xref linkend="sql-commit-prepared"> 명령).
         이 방식을 이용하는 제품으로는 <productname>Pgpool-II</>와 <productname>Continuent Tungsten</>가 있다.
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
   <term>비동기식 다중 운영 서버 복제</term>
   <listitem>

    <para>
         PC와 노트북, PC와 리모트 서버 연결 같이,
         데이터베이스 서버간 연결이 항구적이지 않을 때, 
         그 자료의 정합성을 유지한다는 것은 꽤 고급 기술이다.
         비동기식 다중 운영 서버 환경에서 복제 기능은 다음 문제점을 해결 해야한다.
         각 서버들은 독립적으로 운영되어야하며, 
         주기적으로 트랜잭션 충돌을 피하기 위해 서버간 통신을 
         해야한다. 충돌이 발생하면, 사용자가 해결 할 수 있는 방법을 제공하거나, 
         충돌 해결 정책에 따라 자동으로 해결 할 수 있는 기능이 있어야한다.
         이 방식을 이용하는 제품으로는 Bucardo가 있다.
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
   <term>동기식 다중 운영 서버 복제</term>
   <listitem>

    <para>
         모든 자료 변경이 모든 서버에 바르게 정리 되어야만, 
         다음 작업을 할 수 있도록 구축되기 때문에, 
         자료 변경이 빈번한 환경이라면, 
         단독 운영 서버 구축 환경 보다 성능이 더 떨어질 수 있다.
         읽기 전용 작업이라면, 어느 서버에서도 작업할 수 있다.
         서버간 통신 작업 비용을 줄일기 위해서, 몇 몇 시스템은 
         공유 디스크를 사용하기도 한다. 
         자료 관리 입장에서 본다면, 이 방식이 가장 이상적인 
         방식이다. 하나의 자료 결과에 대해서도 서버간 자료가 공유되기 때문에, 
         <function>random()</> 함수와 같은 것은 문제 없이 사용할 수 있다.
    </para>

    <para>
         <productname>PostgreSQL</>에서는 이 방식의 복제 기능은 제공하지 않는다.
         하지만, <productname>PostgreSQL</> 이중 커밋 two-phase commit
         (<xref linkend="sql-prepare-transaction">, <xref
                       linkend="sql-commit-prepared">) 명령이 이 방식을 
                           구현 하는데 사용될 수 있다.
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
   <term>상용 솔루션</term>
   <listitem>

    <para>
     <productname>PostgreSQL</>은 소스가 공개 되어 있고, 쉽게 확장이 가능하기 때문에, 
         이것을 가지고, 독자적인 기법으로 장애처리, 복제, 부하 분산 기능을 포함 시켜, 
         소스를 공개하지 않은 채 상용으로 판매 할 수 있다. 이렇게 몇몇 솔루션들이 판매되고 있다.
    </para>
   </listitem>
  </varlistentry>

 </variablelist>

 <para>
  다음 <xref linkend="high-availability-matrix"> 표는
  앞에 언급한 다양한 기능들을 요약한 것이다.
 </para>

 <table id="high-availability-matrix">
  <title>고가용성, 부하 분산, 복제 기능 도표</title>
  <tgroup cols="8">
   <thead>
    <row>
     <entry>기능</entry>
     <entry>공유 디스크 장애처리</entry>
     <entry>파일 시스템 복제</entry>
     <entry>트랜잭션 로그 전달</entry>
     <entry>트리거 기반 운영-대기 복제</entry>
     <entry>명령 구문 기반 미들웨어</entry>
     <entry>비동기식 다중 운영 복제</entry>
     <entry>동기식 다중 운영 복제</entry>
    </row>
   </thead>

   <tbody>

    <row>
     <entry>많이 알려진 제품</entry>
     <entry align="center">NAS</entry>
     <entry align="center">DRBD</entry>
     <entry align="center">스트리밍 리플리케이션</entry>
     <entry align="center">Slony</entry>
     <entry align="center">pgpool-II</entry>
     <entry align="center">Bucardo</entry>
     <entry align="center"></entry>
    </row>

    <row>
     <entry>통신 방법</entry>
     <entry align="center">공유 디스크</entry>
     <entry align="center">디스크 블럭</entry>
     <entry align="center">WAL</entry>
     <entry align="center">테이블 로우</entry>
     <entry align="center">SQL</entry>
     <entry align="center">테이블 로우</entry>
     <entry align="center">테이블 로우와 로우 잠금</entry>
    </row>

    <row>
     <entry>특별한 하드웨어 필요없음</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
    </row>

    <row>
     <entry>다중 운영 서버 구축가능</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
    </row>

    <row>
     <entry>운영 서버 측 복제 부하 없음</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
    </row>

    <row>
     <entry>다른 서버들의 지연 없음</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">비동기식일 때</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
    </row>

    <row>
     <entry>운영서버 장애시 자료 손실 없음</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">동기식일 때</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
    </row>

    <row>
     <entry>대기 서버 쪽 읽기전용 허용</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">hot standby 일때</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
    </row>

    <row>
     <entry>테이블 단위 복제가능</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
    </row>

    <row>
     <entry>자료 충돌 해결 작업 필요없음</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
    </row>

   </tbody>
  </tgroup>
 </table>

 <para>
  위에서 소개한 해별 방법 외에도 아래와 같은 방법도 있다:
 </para>

 <variablelist>

  <varlistentry>
   <term>자료 분산</term>
   <listitem>

    <para>
         자료 분산 방식은 하나의 테이블에 보관되는 자료를 여러 테이블로 
         나눠서, 각각의 테이블을 각각의 데이터베이스 서버가 처리하는 방식이다.
         예를 들어, 런던 지사, 파리 지사 자료를 각각의 서버로 처리하는 방식이다.
         만일 런던 지사 자료와, 파리 지사 자료를 합쳐서 조회를 해야한다면, 
         그 일은 응용 프로그램에서 맡던가, 아니면, 읽기 전용 복제 방식을 이용해서, 
         서로 자료를 공유하는 하는 방식을 이용한다.
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
   <term>Multiple-Server Parallel Query Execution</term>
   <listitem>

    <para>
         위에서 언급한 방법들은 여러 서버 쪽으로 여러 쿼리를 사용하는 방법이지, 
         하나의 쿼리를 여러 서버에서 분산 처리하는 방식은 아니다. 
         이 방식으로,
         먼저 중앙 서버가 있고, 한 쿼리는 중앙 서버에서 실행되고, 
         중앙 서버는 각각의 하위 서버로 쿼리를 나눠서 보내고, 
         결과를 중앙 서버가 취합해서 사용자에게 보내주는 방식이 사용된다.
         <productname>Pgpool-II</> 제품이 이런 기능을 사용할 수 있다.
         <productname>PL/Proxy</> 제품도 이런 방식을 사용할 수 있다.
    </para>

   </listitem>
  </varlistentry>

 </variablelist>

 </sect1>


 <sect1 id="warm-standby">
 <title>로그 전달 Log-Shipping 대기 서버</title>


  <para>
   운영 서버에서 만드는 트랜잭션 로그 조각을 
   정기적으로 대기 서버로 옮기고, 그것을 적용시켜, 
   운영 서버가 장애로 멈추게 되면, 
   대기 서버를 운영해서, 가용성을 향상할 수 있다.
   이 기능을 <firstterm>warm standby</>, 또는 
   <firstterm>log shipping</> 기능이라고 한다.
  </para>

  <para>
   이 복제 방식은 먼저, 운영 서버와 대기 서버가 모두 실행 중이어야한다.
   하지만, 두 서버 쌍방간의 연결 상태는 다른 복제 방식보다 나빠도 괜찮다.
   운영 서버는 아카이브 모드로 운영 되어야하며, 
   운영 중에 생기는 다 쓴 WAL 세그먼트 파일(스위칭된 트랜잭션 로그 파일)을
   차례대로 대기 서버로 보내고, 
   대기 서버는 복구 모드 전용(복구가 끝나도 다음 복구 파일이
   있으면 계속 복구 작업을 하는 상태)으로 실행된다.
   이 방식을 이용하면, 데이터베이스 테이블들을 수정해야할 필요가 없다.
   또한 다른 복제 방식에 비해 관리 작업 비용도 적으며, 
   복제 작업이 운영 서버 쪽으로 끼치는 영향도 다른 복제 방식보다 적다.
  </para>

  <para>
   이 방식의 구현 방법은 간단하다. 운영 서버에서 다 쓴 WAL 파일을 
   다른 서버로 운송(shipping) 하는 것 뿐이다.
   <productname>PostgreSQL</>에서는 그 로그 옮기는 작업은 한 번에 
   하나의 로그 파일을 옮길 수 있도록 구현되어 있다.
   WAL 파일(16MB)을 옮기는 작업은 데이터베이스 서버 밖에서 
   관리자가 정의한 방식으로 진행 되기 때문에, 
   같은 사이트 내로 옮겨도 되고, 전혀 다른 시스템 쪽으로 보내도 되고, 
   여러 시스템으로 한꺼번에 보내도 된다. 이 부분은 전적으로 관리자에게 
   맡긴다. 단지 고려해야할 사항은 파일이 전송될 때의 
   전송량 때문에 운영 서버에 영향을 줄 수도 있다. 이 부분이 염려되면, 
   전송 속도를 제한 할 수 있는 방법도 고려해야할 것이다.
   아니면, 레코드 기반 로그 전달 방식 (스트리밍 복제)을 고려할 수 도 있다.
   (<xref linkend="streaming-replication"> 참조)
  </para>

  <para>
   로그 전달 방식은 비동기식임을 기억해야 한다.
   다시 말하면, 전송하는 WAL 내용은 이미 커밋된 자료이기 때문에, 
   그 자료가 대기 서버로 미쳐 전달 되기전에 운영 서버가 멈춰버리면, 
   그 자료는 손실 된다. 자료 손실량을 줄이는 방법으로 
   <varname>archive_timeout</varname> 환경설정값을 몇 초 정도로 짧게 
   지정해 자주 사용하는 WAL 파일을 바꾸고, 그것을 전송하면, 
   되겠지만, 그 파일의 크기가 16MB이기 때문에, 잦은 WAL 파일 전송 작업으로
   네트워크 사용량이 증가할 것이다.
   스트리밍 복제 방식(<xref linkend="streaming-replication"> 참조)을 
   이용하면, 이 손실 되는 자료량을 최소화 할 수 있다.
  </para>

  <para>
  (물론 위에서 언급한 한계점이 있기는 하지만,)
   대기 서버로 넘어 오는 WAL 파일이 제때에 잘 넘어 온다면, 
   운영 서버가 중지 되어 대기 서버가 그 역할을 맡기까지 서비스가 
   중지되는 시각은 극히 짧다. 이렇게 가용성을 향상 시킨다.
   베이스 백업 자료를 준비하고, 지금까지 보관해둔 WAL 파일을 
   가지고, 서버를 복구 하는 방법은 이 방식보다 꽤 많은 서비스 중지 시간이 
   필요할 것이다. 서버가 복구 되는 기술적인 방식은 동일하지만, 
   가용성 입장에서는 차이가 난다.
   warm standby 방식으로 구현되면, 대기 서버 쪽에서는 
   어떤 쿼리도 사용할 수 없다. 대기 서버 쪽에서 
   읽기 전용 쿼리를 사용하려면, hot standby 방식으로 구축해야한다.
   이 부분은 <xref linkend="hot-standby">에서 자세히 설명한다.
  </para>

  <indexterm zone="high-availability">
   <primary>warm standby</primary>
  </indexterm>

  <indexterm zone="high-availability">
   <primary>PITR standby</primary>
  </indexterm>

  <indexterm zone="high-availability">
   <primary>standby server</primary>
  </indexterm>

  <indexterm zone="high-availability">
   <primary>log shipping</primary>
  </indexterm>

  <indexterm zone="high-availability">
   <primary>witness server</primary>
  </indexterm>

  <indexterm zone="high-availability">
   <primary>STONITH</primary>
  </indexterm>

  <sect2 id="standby-planning">
   <title>계획</title>

   <para>
    일반적으로 데이터베이스 시스템을 구축할 때, 
        운영 서버와 대기 서버를 함께 구축한다면, 
        그 두 서버 환경은 최대한 비슷한 환경으로 구축하는 것이 
        제일 좋다. 물론 하드웨어 사양은 틀려도 크게 문제가 되지 않으나, 
        테이블스페이스 문제를 고려했을 때만 보아도, 
        운영 서버에서 <xref linkend="sql-createtablespace"> 명령으로
        테이블스페이스를 조작할 일이 생겼을 때, 
        대기 서버에서도 똑 같은 작업이 정상적으로 진행되려면, 
        운영 서버와 같은 디렉토리 구조를 가지고 있어야한다.
    물론 운영체제 전체를 운영하는 입장에서 본다면, 
        하드웨어와 운영체제도 똑 같은 사양이면, 보다 쉽게 운영 할 수 있을 것이다.
        하드웨어 머신 아키텍쳐는 같아야한다. 로그 전달 방식의 복제를 사용할 경우, 
        운영 서버가 64bit이다면, 거기서 만든 로그 파일은 32bit 대기 서버에서는
        사용할 수 없다.
   </para>

   <para>
    일반적으로 로그 전달 방식 복제는 메이져 버전이 서로 다른 
        <productname>PostgreSQL</> 서버 간은 구현이 불가능하다.
        디스크 자료 저장 포멧이 바뀔 경우에, 
        PostgreSQL 개발 그룹에서는 메이져 버전을 바꾸어 릴리즈하는 것이 
        정책이기 때문이다. 물론 마이너 버전의 서로 틀린 경우는 이 복제 
        환경을 구축해도 잘 작동할 것이다. 이렇게 서로 마이너 버전이 틀린 경우
        해결 하기 힘든 예상치 못한 문제가 발생할 수도 있기 때문에, 
        가능하다면, 운영 서버와 대기 서버의 버전을 최대한 같은 것을 사용하길 
        권장한다.
        마이너 버전 업데이트가 필요하다면, 이 작업의 가장 좋은 순서는 
        먼저 대기 서버 쪽을 업데이트해서, 옛 버전의 WAL 파일을 잘 적용할 수 있는지
        부터 확인하고, 운영 서버를 업데이트한다.
   </para>

  </sect2>

  <sect2 id="standby-server-operation">
   <title>대기 서버 동작방식</title>

   <para>
    서버가 대기 모드로 실행되면, 
        서버는 마스터 서버에서 받는 WAL 파일을 계속해서 자신의 서버에 
        반영하는 작업만 한다. 대기 서버는 운영 서버가 보내는 파일을 보관해 두는 
        디렉토리에 새 WAL 파일이 있는지 확인해서, 새 WAL 파일을 반영하는 방식(warm standby)도 있고
        (<xref linkend="restore-command"> 참조), 
        TCP 연결 방식을 이용해서 운영 서버와 직접 연결하고, 커밋된 트랜잭션을 
        즉시 대기 서버로 반영하는 방식(스트리밍 복제)도 있다.
        또 내부적으로 보면, 대기 서버의 <filename>pg_xlog</> 디렉토리에 있는 
        WAL 파일을 참조하는 경우도 있다. 이 경우는 스트리밍 복제 환경에서 
        운영 서버에서 보낸 트랜잭션을 미쳐 반영하기 전에 대기 서버가 중지 되었다가 
        다시 실행될 경우에 일어난다. 물론 관리자가 직접
        <filename>pg_xlog</> 디렉토리에 직접 WAL 파일을 두고 서버를 실행할 수도 있다.
   </para>

   <para>
    대기 서버가 실행되면, 제일 먼저 <varname>restore_command</> 설정값에 지정된
        명령어를 진행한다. 적용 해야할 WAL 세그먼트 파일이 아카이브 디렉토리에 
        있는지 확인하고 있으면 차례대로 적용한다. 이 작업이 끝나고 더 이상 
        적용할 파일이 없으면 <varname>restore_command</> 설정값에 지정된 
        명령은 실패로 끝나야한다. 그러면, 
        복구 환경이 스트리밍 복제 방식이라면, 운영 서버 쪽으로 접속 해서, 
        운영 서버가 데이터베이스 연결을 통해 보내는 트랜잭션들을 자신의
        <filename>pg_xlog</> 디렉토리 내 해당 WAL 로그 파일에 추가한다.
        다음부터는 서버가 알아서 해당 작업을 수행하고, 
        커밋 되었다고 기록하고, 체크포인트 작업을 하는 등 일련의 자료 변경 작업을 수행한다.
        반면, 복구 환경이 warm standy 방식이라면, <varname>restore_command</> 설정값에 지정된
    명령이 실패로 끝나면, 원하는 WAL 세그먼트 파일이 새롭게 생길 때까지 기다렸다가 생기면, 
        다시 작업을 하고, 또 더 이상 없으면 실패로 끝나면서 대기하는 작업을 반복한다.
        이 반복 작업은 서버가 중지되거나, 대기 작업을 이제 그만 하고 스스로 독립된 
        운영 서버 역할을 하라고 알려주는 트리거 파일이 생기기 전까지 계속 반복된다.
   </para>

   <para>
    대기 모드는  <command>pg_ctl promote</> 명령을 실행하거나, 
        트리거 파일(<varname>trigger_file</> 설정값에 지정한 파일)이 
        생기면 끝난다. 물론 적용해야할 WAL 파일이, 
        아카이브 디렉토리에 아직 있거나, <filename>pg_xlog</> 디렉토리 내에 
        있다면, 이것들을 모두 적용하고 대기 모드를 끝낸다.
        이때 스트리밍 복제를 위한 운영 서버와의 연결도 더 이상 재시도하지 않는다.
   </para>
  </sect2>

  <sect2 id="preparing-master-for-standby">
   <title>대기 서버 구축을 위한 운영 서버 준비작업</title>

   <para>
    첫번째 작업은 대기 서버로 보낼 WAL 세그먼트 파일을 그냥 버리지 않고, 
        달리 처리하는 설정을 해야한다. 이 방법에 대한 자세한 이야기는 
        <xref linkend="continuous-archiving">에서 하고 있다.
        그냥 버리지 않고 다르게 처리 한다는 것은 
        그 WAL 세그먼트 파일이 운영 서버가 중지되어도 대기 서버가 
        사용할 수 있는 위치로 옮겨 놓는다는 것을 의미한다. 
        이 방법에는 여러 방법이 있을 수 있다. 단순히 네트워크 드라이브에 
        복사를 하는 방법도 있을 수 있고, FTP를 이용해서, 대기 서버의 원하는 
        디렉토리로 업로드 하는 방법도 있고, 백업용 테이프 드라이브 쪽으로 보내는 
        방법도 있을 것이다. 중요한 것은 운영 서버를 더이상 사용할 수 없을 때도
        대기 서버는 그 WAL 세그먼트 파일들을 사용할 수 있어야한다는 점이다.
   </para>

   <para>
    스트리밍 복제 방식을 사용하려면, 
        대기 서버에서 요청하는 데이터베이스 접속을 허용하도록 설정하는 작업을 해야한다.
        총 세가지 작업인데, 첫번째는 접속 계정의 권한을 복제 기능을 사용할 수 있도록 해야하고, 
        두번째는 <filename>pg_hba.conf</> 파일에 대기 서버가 운영되는 
        호스트가 등록되어야하고, 그곳에 데이터베이스 항목은 <literal>replication</>으로 
        지정되어야하며, 세번째는 서버 환경 설정에서 <varname>max_wal_senders</> 값이 
        대기 서버의 연결수 만큼은 지정되어야한다.
   </para>

   <para>
    대기 서버를 실행하려면, 먼저 운영서버의 베이스 백업을 준비해야한다.
        이것에 대한 자세한 이야기는 <xref linkend="backup-base-backup">에서 다룬다.
   </para>
  </sect2>

  <sect2 id="standby-server-setup">
   <title>대기 서버 구축하기</title>

   <para>
    대기 서버를 구축하려면, 먼저 운영서버의 베이스 백업 자료를
        복원해야한다(<xref linkend="backup-pitr-recovery"> 참조).
        다음 대기 서버의 데이터 클러스터 디렉토리 안에 
        <filename>recovery.conf</> 파일 파일을 만들고, 그 파일 안에, 
        <varname>standby_mode</> 값을 on으로 설정하며,
        <varname>restore_command</> 값으로 대기 서버로 보내진 WAL 세그먼트 
        파일을 대기 서버에서 사용할 수 있도록 가져오는 명령을 지정한다.
        고가용성을 고려해서, 대기 서버가 여럿 있는 경우는
        <varname>recovery_target_timeline</> 값으로 <literal>latest</>를 
        지정한다. 이렇게 해서, 대기 서버 가운데 몇 번 재실행 되었던 
        서버도 정상적으로 운영 서버의 작업 내용을 반영 할 수 있도록 한다.
   </para>

   <note>
     <para>
         여기서 설명하는 구축 방법을 사용할 때는, 
         pg_standby나 기타 다른 복제 툴들을 사용하면 안된다.
         <varname>restore_command</> 설정값으로 지정하는 명령은 
         작업할 파일이 없을 경우 즉시 종료될 수 있는 것을 사용해야한다.
         서버 쪽에서 이 명령의 재실행 처리를 관리하기 때문이다.
         pg_standby 명령을 사용하려면, <xref linkend="log-shipping-alternative">을 
         참조하라.
    </para>
   </note>

   <para>
     스트리밍 복제 기능을 사용하려면, 
         <varname>primary_conninfo</> 설정값을 지정해야한다.
         이 값은 libpq 라이브러리에서 사용하는 데이터베이스 연결 문자열이다.
         이 값에는 운영서버의 호스트 이름(또는 IP 주소)은 반드시 지정해야하며, 
         그 외 접속에 필요한 정보를 지정한다.
         운영 서버에서 데이터베이스 접속을 계정 비밀번호를 입력해야한다면, 
         이곳에 그 비밀번호를 지정하거나, 대기 서버를 실행하는 시스템 계정의
         홈 디렉토리에 .pgpass 파일에 지정하면 된다.
   </para>

   <para>
    만일 대기 서버가 고가용성을 고려해서 구축되는 경우라면, 
        대기 서버의 서버 환경도 운영 서버와 똑같이 아카이브 모드로 운영되어야하며, 
        서버 접근 인증 설정도 운영 서버와 같아야한다.
        왜냐하며, 운영 서버 장애가 발생하면 이 대기 서버가 운영 서버 역할을 해야하기 때문이다.
   </para>

   <para>
    운영 서버에서 넘겨 받은 WAL 파일을 사용한다면, 
        <xref
            linkend="archive-cleanup-command"> 설정으로 더 이상 필요없는,
                이미 대기 서버에 반영이 완료된 파일을 지워서, 
                디스크 공간을 확보 할 수도 있다.
                이 설정값으로 <application>pg_archivecleanup</> 명령을 이용하면, 
                보다 쉽게 이 작업을 할 수 있다.
                이 명령에 대한 자세한 설명은 <xref linkend="pgarchivecleanup"> 명령
                도움말을 참조하라.
    반면, 대기 서버가 운영 서버의 백업 용도로 구성한다면, 
        운영 서버의 베이스 백업 뒤로 생긴 모든 WAL 세그먼트 파일을 지우지 않는 것이 
        좋다. 설령 그 파일이 대기 서버로 모두 반영되었다 하더라도, 
        어떤 방식으로 다시 복원 작업을 할지 모르기 때문에 모두 남겨두라.
        물론 베이스 백업이 바뀌었다면, 이 베이스 백업 이전 로그 파일들은 기록 보관용적인 자료가 아니라면
        삭제해도 무방할 것이다.
   </para>

   <para>
    윗 내용을 참고해서, 대기 서버로 구축하기 위한 서버의 <filename>recovery.conf</> 
        파일은 일반적으로 아래와 같은 내용으로 구성한다:
<programlisting>
standby_mode = 'on'
primary_conninfo = 'host=192.168.1.50 port=5432 user=foo password=foopass'
restore_command = 'cp /path/to/archive/%f %p'
archive_cleanup_command = 'pg_archivecleanup /path/to/archive %r'
</programlisting>
   </para>

   <para>
    대기 서버는 다중으로 구성할 수 있지만, 스트리밍 복제 방식을 이용한다면, 
        운영 서버의 <varname>max_wal_senders</> 환경 설정값으로
        이 대기 서버 모두가 동시에 접속 할 수 있도록 충분한 연결을 확보해야한다.
   </para>

  </sect2>

  <sect2 id="streaming-replication">
   <title>스트리밍 복제</title>

   <indexterm zone="high-availability">
    <primary>스트리밍 복제</primary>
   </indexterm>

   <para>
    스트리밍 복제는 WAL 세그먼트 파일 전달 방식보다 
        운영 서버의 자료 상태를 거의 실시간으로 동기화 한다.
        대기 서버는 운영 서버로 접속해서, WAL 레코드 단위로 그 정보를 가져오고, 
        그것을 반영하기 때문이다. WAL 세그먼트 파일 전달 방식을 이용하면, 
        운영 서버가 그 로그 파일을 다 채워서 다른 로그 파일을 쓰겠다고 하는 
        시점에 대기 서버로 옮겨지기 때문에, 그 동안은 대기 서버와 
        운영 서버 사이의 자료 불일치가 일어난다.
   </para>

   <para>
    스트리밍 복제 방식은 기본적으로 비동기식으로 이루워진다. 
        (<xref linkend="synchronous-replication"> 참조)
        그래서, 운영 서버와 대기 서버간의 자료 불일치가 약간 있을 수는 있다.
        하지만 대기 서버와 운영 서버 사이의 네트워크 환경이 
        양호하고, 대기 서버의 성능이 좋다면, 파일 기반 로그 전달 방식과는
        비교도 안될 만큼 1초 미만의 지연시간이 생긴다.
        운영 서버와 대기 서버가 같은 네트워크 대역대 안에 있다면, 
        거의 실시간으로 동기화 된다. 스트리밍 복제 환경에서는 
        <varname>archive_timeout</> 설정값을 짧게 해서, 자료 손실을 줄이겠다는 
        설정이 필요 없다.
   </para>

   <para>
    파일 기반 로그 전달 방식을 함께 사용하지 않고, 
        단지 스트리밍 복제 기능만 사용한다면, 
        운영 서버에서 반드시  <varname>wal_keep_segments</> 환경설정값을 
        지정해서, 아직 대기 서버로 반영되지 못한 WAL 파일을 남겨두는 최대 
        개수를 지정해 주어야한다. 운영 서버에는 WAL 파일을 재활용하기 때문에, 
        대기 서버의 중지 시간이 길어져, 이 대기 서버로 반영되지 못한 WAL 파일이 
        계속 쌓이면 사용할 수 있는 디스크 공간이 점점 줄어들 것이다. 
        또한 대기 서버의 중지 시간이 아주 길어졌고, 운영 서버쪽에서는 
        더 이상 로그를 보관할 수 없어 재활용 해 버렸다면, 더 이상 동기화 할 자료를 
        찾지 못하기 때문에 다시 대기 서버를 구축 해야한다.
    만일 운영 서버 쪽에서 WAL 세그먼트 로그 파일을 대기 서버 쪽으로 보내는 
        설정을 해 두었고, 대기 서버 쪽에서 그 파일을 사용할 수 있는 환경이라면, 
        <varname>wal_keep_segments</> 설정은 굳이 필요가 없다. 
        대기 서버 쪽으로 처리되어야할 WAL 로그 파일들은 로그 전달 설정을 통해서 
        이미 대기 서버 쪽으로 옮겨졌기 때문에, 충분히 운영 서버의 자료와 
        동기화 할 수 있을 것이다.
   </para>

   <para>
    이런 이유로, 스트리밍 복제 기능을 이용 할 때도, 
        먼저 대기 서버에서 파일 기반 로그 전달 기능도 함께 설정 하는 것이 
        좋다. 자세한 것은 <xref linkend="warm-standby">에서 설명하고 있다.
        파일 기반 로그 전달 방식에서 스트리밍 복제 방식으로 바뀌려면, 
        <filename>recovery.conf</> 파일에서 <varname>primary_conninfo</>
        설정값에 접속할 운영 서버의 정보를 지정하면 된다.
        운영 서버에서는 대기 서버가 접속할 수 있도록
        <xref linkend="guc-listen-addresses"> 환경설정값이 바뀌어야하며, 
        <filename>pg_hba.conf</> 파일에 대기 서버에서의 접속을 허용할 
        있도록 지정하며, 그 때 사용할 데이터베이스 이름은 <literal>replication</>
        으로 지정한다. 자세한 사항은 <xref linkend="streaming-replication-authentication">
        을 참조하라.
   </para>

   <para>
    또한, 운영 서버 입장에서  클라이언트의 TCP 연결이 끊겼을 경우, 
        빠르게 그 소켓을 정리해서, TCP 연결을 원할하게 하기 위해, 
        <xref linkend="guc-tcp-keepalives-idle">, <xref linkend="guc-tcp-keepalives-interval">,
        <xref linkend="guc-tcp-keepalives-count"> 설정값을 조정할 수도 있다.
   </para>

   <para>
    또한 대기 서버의 최대 동시 연결수도 지정해야한다.
    (<xref linkend="guc-max-wal-senders"> 환경설정값 항목을 참조).
   </para>

   <para>
    대기서버는 먼저 운영 서버에서 넘겨 받은 WAL 세그먼트 파일을 모두 
        자신의 서버에 적용하면, <varname>primary_conninfo</> 설정값에 지정한 
        운영 서버로 접속한다. 이 접속이 성공하면, 대기 서버는 
        walreceiver 프로세스를 만들어 운영 서버의 walsender 프로세스에서 
        보내는 트랜잭션 정보를 하나씩 받아서 자신의 서버에 적용한다.
   </para>

   <sect3 id="streaming-replication-authentication">
    <title>인증</title>
    <para>
         WAL 스트리밍 정보는 보안상 슈퍼유저나  인증된 데이터베이스 사용자만 
         사용할 수 있어야한다. 이 권한을 부여하려면, <literal>REPLICATION</> 권한을 
         부여한다. 그래서, 대기 서버에서 운영 서버로 접속하는 데이터베이스 
         사용자는 <literal>LOGIN</> 권한과, <literal>REPLICATION</>
         권한을 반드시 지정해야한다. 이 리플리케이션 전용 사용자는 운영 서버의 자료를
         조작할 수 없도록 슈퍼유저가 아닌 별개의 사용자를 만들어 사용하는 것이 
         보안상 안전하다. 
    </para>

    <para>
         스트리밍 복제 기능을 이용하기 위한 운영 서버의 클라이언트 인증은 
         <filename>pg_hba.conf</> 파일에서 해당 데이터베이스 이름으로 
         <literal>replication</> 이라는 예약어를 지정해야한다.
         예를 들어서, 대기 서버의 IP가 <literal>192.168.1.100</> 이라면, 
         운영 서버의 <filename>pg_hba.conf</> 파일은 다음과 같은 
         형식으로 지정한다:

<programlisting>
# 아래 "foo" 는 스트리밍 복제를 위해 대기 서버가 사용할 운영 서버로 접속할
# 데이터베이스 사용자 이름이다. 인증 방식은 md5 비밀번호 인증을 사용한다.
# 그 대기 서버의 IP는 192.168.1.100 딱 하나다.
#
# TYPE  DATABASE        USER            ADDRESS                 METHOD
host    replication     foo             192.168.1.100/32        md5
</programlisting>
    </para>
    <para>
         대기 서버 입장에서 접속할 운영 서버 접속 정보는 
         <filename>recovery.conf</> 파일에서 지정한다.
         접속할 데이터베이스 사용자의 비밀번호는 
         이 파일에 지정해도 되고, 대기 서버를 실행하는 시스템 사용자의 
         홈 디렉토리에 있는 <filename>~/.pgpass</> 파일에서 지정해도 된다.
         (이 때 데이터베이스 이름으로 <literal>replication</> 예약어를 사용한다.)
         예를 들어, 운영 서버의 IP는 <literal>192.168.1.50</>,
         포트는 <literal>5432</literal>, 데이터베이스 사용자는 
         <literal>foo</>, 그 사용자의 비밀번호는 <literal>foopass</>인 경우,
         대기 서버에서 사용하는 <filename>recovery.conf</> 파일에 
         다음과 같이 지정한다:

<programlisting>
# 이 대기 서버는 호스트 IP 192.168.1.50, 포트 5432 운영 서버로
# "foo" 사용자, "foopass" 비밀번호로 접속한다.
primary_conninfo = 'host=192.168.1.50 port=5432 user=foo password=foopass'
</programlisting>
    </para>
   </sect3>

   <sect3 id="streaming-replication-monitoring">
    <title>모니터링</title>
    <para>
         복제 환경의 모니터링 가운데 가장 중요한 사항은 
         운영 서버에서 만들어내는 WAL 레코드들이 
         얼마나 잘 대기 서버로 반영 되고 있느냐를 살펴보는 것이다.
         이 작업은 운영 서버의 현재 WAL 쓸 위치와, 
         대기 서버의 마지막 처리된 WAL 쓸 위치 차이를 계산하는 방식을 
         이용하면 된다. 이 작업을 위해서, 
         운영 서버에서는 <function>pg_current_xlog_location</>, 
         대기 서버에서는 <function>pg_last_xlog_receive_location</> 두 함수를
         사용한다. (이 함수의 구체적인 사용법은 
         <xref linkend="functions-admin-backup-table">,
         <xref linkend="functions-recovery-info-table">에서 다룬다.)
         대기 서버에서 마지막 받은 WAL 위치는 OS의 프로세스를 확인하는 
         <command>ps</> 명령으로 출력되는 WAL receiver 프로세스의 
         이름에서도 확인할 수 있다. (프로세스 모니터링에 대한 자세한 이야기는
         <xref linkend="monitoring-ps">을 참조)
    </para>
    <para>
         또한 운영 서버에서 사용하는 WAL sender 프로세스의 정보는 
         <link linkend="monitoring-stats-views-table"></> 뷰로 확인할 수 있다.
         이 뷰에서 <function>pg_current_xlog_location</> 값과, 
         <literal>sent_location</> 값이 차이가 많이 나면, 
         운영 서버가 많이 바쁜 상황이고, 
         <literal>sent_location</> 값과, <function>pg_last_xlog_receive_location</>
         값이 차이가 많이 나면, 대기 서버가 많이 바쁘거나, 
         네트워크 상황이 좋지 않은 경우다.
    </para>
   </sect3>
  </sect2>

  <sect2 id="streaming-replication-slots">
   <title>복제 슬롯</title>
   <indexterm>
    <primary>replication slot</primary>
    <secondary>streaming replication</secondary>
   </indexterm>
   <indexterm>
    <primary>복제 슬롯</primary>
    <secondary>스트리밍 복제</secondary>
   </indexterm>
   <para>
    대기 서버가 운영 서버로부터 복제 해야 할 내용을 미처 다 복제 하기도 전에
    운영 서버가 자신의 트랜잭션 로그를 버리는 문제를 막을 수 있는 방법으로
    복제 슬롯을 이용하면 된다.  또한 대기 서버와 운영 서버간 연결이 끊겨서
    <link linkend="hot-standby-conflict">복구 충돌</>이 발생하는 상황에서도 
    운영 서버의 자료가 지워지는 것을 방지 할 때 이 기능을 이용할 수 있다.
   </para>
   <para>
    이전 버전(9.3 이하)까지는 대기 서버로 전달 할 트랜잭션
    로그를 전달하지 못할 경우
    최대 <xref linkend="guc-wal-keep-segments"> 환경 설정값에 지정된 개수 만큼만    더 보관하고 있어 더 오래된 트랜잭션 로그를 대기 서버가 필요로 하는 경우
    대기 서버를 다시 구축해야 했었다.  또한 
    <xref linkend="guc-archive-command"> 환경 설정값에 지정된 명령어로 
    트랜잭션 로그를 보관하는 부분에서도 마찬가지였다.
    이제 복제 슬롯을 이용하면, 장시간 트랜잭션 로그를 전달 받지 못해 대기
    서버를 다시 만들어야 하는 문제를 피해 갈 수 있게 되었다. 
    하지만, 이 방법을 이용하게 되면 예상치 않게 트랜잭션 로그 파일의 개수가
    많아질 수도 있다. 물론 대기 서버와 동기화를 위한 옛 트랜잭션 로그만 보관
    하지만,  이 기능을 사용하고 할 때는 <literal>pg_xlog</> 디렉토리의
    여유 공간을 충분히 확보해야 할 것이다. 현재로써는 트랜잭션 로그를 남기면서
    이 디렉토리의 여유 공간을 항상 일정하게 유지할 수 있는 방법은 없다.
   </para>
   <para>
    비슷하게, 이전 버전에서도 제공하고 있던
    <xref linkend="guc-hot-standby-feedback"> 또는
    <xref linkend="guc-vacuum-defer-cleanup-age"> 설정 값을 이용해서
    vacuum 작업으로 인한 관계된 자료가 지워지는 문제점을 막을 수는 있었지만,
    대기 서버 단절 시간이 길어 질 때는 방법이 없었다. 
    복제 슬롯은 이런 단점을 극복했다.
   </para>
   <sect3 id="streaming-replication-slots-manipulation">
    <title>복제 슬롯 조회 및 관리</title>
    <para>
     각각의 복제 슬롯에는 이름을 부여한다. 이름은 소문자, 숫자, 밑줄(_)
     조합으로 구성한다.
    </para>
    <para>
     운영 서버에서 사용하고 있는 복제 슬롯 관련 정보는
     <link linkend="catalog-pg-replication-slots"><structname>pg_replication_slots</structname></link> 뷰에서 제공한다.
    </para>
    <para>
     슬롯은 스트리밍 복제 프로토콜(<xref linkend="protocol-replication"> 참조)
     과 SQL 함수(<xref linkend="functions-replication"> 참조) 로 만들거나 
     삭제 할 수 있다.
    </para>
   </sect3>
   <sect3 id="streaming-replication-slots-config">
    <title>설정 예제</title>
    <para>
     먼저 운영 서버에서 아래와 같은 슬롯을 하나 만든다:
<programlisting>
postgres=# SELECT * FROM pg_create_physical_replication_slot('node_a_slot');
  slot_name  | xlog_position
-------------+---------------
 node_a_slot |

postgres=# SELECT * FROM pg_replication_slots;
  slot_name  | slot_type | datoid | database | active | xmin | restart_lsn
-------------+-----------+--------+----------+--------+------+-------------
 node_a_slot | physical  |        |          | f      |      |
(1 row)
</programlisting>
     다음은 대기 서버의 <filename>recovery.conf</> 파일에, 
     아래와 같이 그 슬롯 이름을 <varname>primary_slot_name</>
     설정 값으로 지정한다:
<programlisting>
standby_mode = 'on'
primary_conninfo = 'host=192.168.1.50 port=5432 user=foo password=foopass'
primary_slot_name = 'node_a_slot'
</programlisting>
    </para>
   </sect3>
  </sect2>

  <sect2 id="cascading-replication">
   <title>순차적 복제</title>

   <indexterm zone="high-availability">
    <primary>Cascading Replication</primary>
   </indexterm>
   <indexterm zone="high-availability">
    <primary>순차적 복제</primary>
   </indexterm>


   <para>
    순차적 복제 cascading replication 기능은 대기 서버가 
    마치 이어 달리기처럼 다른 대기 서버의
    스트리밍 복제를 할 수 있도록 하는 것이다.
    이 기능은 스트리밍 복제에 필요한 운영 서버의 부하를 최소화 할 수 있다.
   </para>

   <para>
    대기 서버가 트랜잭션 로그를 받음과 동시에 또 다른 대기 서버로 보낼 수 있음을
    의미한다.  이렇게 전달하는 방식을 순차적 복제라고 하며, 
    운영 서버에서 복제 정보를 받아오는 서버를 업스트림 서버라고 하고, 
    그 서버로부터 정보를 받아가는 서버를 다운스트림 서버라고 한다.
    순차적 복제에서 다운스트림 서버수는 제한이 없다. 마치 기존 하나의 운영 서버에
    여러 대의 대기 서버를 연결해서 복제를 구현 하는 것 같다.
   </para>

   <para>
    순차적 복제에서는 운영서버에 만든 트랜잭션 로그 레코드를 전달하는 것뿐만
    아니라, 아카이빙 모드로 보관된 로그들도 함께 전달한다.
    그래서 업스트림 서버와의 연결이 끊기더라도, 자신의 트랜잭션 로그는 
    다운스트림 서버 쪽으로 모두 보낸다. (하위 노드 입장에서 보면 
    자신의 상위 노드가 대기 서버에서 운영 서버로 전환되어 새로운 
    트랜잭션 로그를 만들어도 여전히 복제를 할 수 있음을 뜻한다. - 옮긴이)
   </para>

   <para>
    순차적 복제 기능은 현재 비동기식으로 구현되었다. 동기식 복제
    설정(<xref linkend="synchronous-replication"> 참조)을 하더라도 
    순차적 복제 기능을 이용한다면, 그 설정은 무시된다.
   </para>

   <para>
    대기 서버의 <varname>hot_standby_feedback</> 설정은 순차적 복제 환경에서도
    그대로 작동 한다.
   </para>

   <para>
    업스트림 대기 서버가 새로운 운영 서버가 된다면, 
    다운스트림 대기 서버의 <varname>recovery_target_timeline</>
    설정값이 <literal>'latest'</>이면 새 운영 서버로부터 복제를 
    계속한다.
   </para>

   <para>
    순차적 복제 기능을 사용하려면, 업스트림 서버 쪽에서는 
    기본적인 복제 기능을 위해 운영 서버 쪽에서 설정했던 것을 
    그대로 설정하며 (<xref linkend="guc-max-wal-senders">,
    <xref linkend="guc-hot-standby"> 설정값 조정하고,
    <link linkend="auth-pg-hba-conf">호스트 기반 인증</link>
    설정을 한다), 다운스트림 대기 서버는 기존 대기서버 설정과 같이
    하면서 <varname>primary_conninfo</> 설정에서 업스트림 대기 서버
    정보를 지정하면 된다.
   </para>
  </sect2>

  <sect2 id="synchronous-replication">
   <title>동기식 복제</title>

   <indexterm zone="high-availability">
    <primary>동기식 복제</primary>
   </indexterm>

   <indexterm zone="high-availability">
    <primary>Synchronous Replication</primary>
   </indexterm>

   <para>
    <productname>PostgreSQL</> 스트리밍 복제 기능은 
        기본이 비동기식이다. 이 말은 
        운영 서버가 장애로 멈추어, 
        대기 서버가 운영 서버로 역할 전환 작업(failover, 장애처리)을 
        할 때, 운영 서버와 대기 서버 사이 자료 동기화에 지연이 있었다면, 
        그 만큼의 자료를 잃어버린다는 뜻이다.
   </para>

   <para>
    동기식 복제 방식은 하나의 트랜잭션을 대기 서버에 반영하고, 
        그 결과를 운영 서버가 확인하는 방식이다. 
        이 방식은 트랜잭션 커밋으로 제공하는 기본 자료 안정성을 더 확장한 것이다.
        이것을 컴퓨터 과학 이론에서는 이중 복제라한다.
   </para>

   <para>
    동기식 복제 기능을 이용하면, 
        운영 서버, 대기 서버 모두 트랜젹션이 트랜잭션 로그 파일에 
        기록되었을 경우에만 정상처리 되었다고 판단한다.
        이렇게 하면, 운영 서버가 중지 되어도 대기 서버에서 
        자료 손실이 일어나지 않는다. 이렇게 해서, 
        자료의 안정성을 제공하지만, 
        대기 서버의 작업 완료 응답을 확인하는 작업까지 포함되어
        운영 서버의 복제 기능을 이용하는 비용이 상대적으로 늘어난다.
        직렬화 된 트랜잭션 전달 작업은 현재 전달할 트랜잭션의 응답을 받아야
        다음 작업을 진행하기 때문에, 최소한 그 만큼의 지연시간이 생길 수 밖에 없다.
   </para>

   <para>
    읽기 전용 트랜잭션과, 트랜잭션 롤백은 대기 서버의 응답을 받지 않는다.
        최 상위 레벨의 트랜잭션에 대해서 응답을 확인하지, 
        그 하위 레벨 트랜잭션인 서브트랜잭션에 대해서는 응답을 확인하지 않는다.
        대량 자료 등록이나, 인덱스 생성 작업 같이 시간이 많이 걸리는 
        트랜잭션에 대해서도 대기 서버의 마지막 커밋 메시지를 확인하지 않는다. 
        이중 커밋(2PC)에 대해서는 모든 작업에 대해서 확인한다.
   </para>

   <sect3 id="synchronous-replication-config">
    <title>기본 환경설정</title>

   <para>
    이미 복제 기능을 사용하고 있는데, 
        동기식 복제 방식으로 변경하려면, <xref linkend="guc-synchronous-standby-names"> 
        설정값을 비워두지 않으면 된다. 
        <varname>synchronous_commit</> 설정값도 <literal>on</>이어야하지만, 
        이 값이 기본값이 때문에 실질적으로는 윗 환경설정 파라미터만 지정하면 된다.
        (<xref linkend="runtime-config-wal-settings"> 과 
        <xref linkend="runtime-config-replication-master"> 참조)
        동기식 복제 사용하는 대기 서버를 지정하면, 
        그 대기 서버로 보내는 모든 커밋 작업은 대기 서버에서도
        커밋 작업을 완료했다는 응답을 기다린다. 이 응답을 확인 해야 
        운영 서버의 다음 커밋 작업을 진행한다.
        <varname>synchronous_standby_names</> 설정값은 쉼표 구분 여러 개의 
        대기 서버 이름을 지정할 수 있으며, 여기 등록되지 않은 대기 서버는 
        동기식 복제를 하지 않는다.
        <varname>synchronous_commit</> 설정은 환경 설정 파일에서 변경할 수 
        있을 뿐만 아니라,
        각 트랜잭션에 대한 각각의 내구성 보장 방법을 개별적으로 설정할 수 있도록
        개별 사용자나, 특정 데이터베이스나, 아니면, 특정 응용 프로그램에서 
        이 값을 필요할 때 변경할 수 있다.
   </para>

   <para>
    커밋 레코드가 운영 서버 WAL 세그먼트 파일에 기록된 뒤에, 
        그 레코드를 대기 서버로 보낸다.
        대기 서버는 그 레코드를 자신의 WAL 세그먼트 파일에 기록한 뒤에, 
        <varname>wal_receiver_status_interval</> 환경설정 값이 0으로
        지정되어 있지 않으면, 운영 서버로 작업을 완료했다고 메시지를 보낸다.
        대기 서버 가운데, 운영 서버에서 <varname>synchronous_standby_names</>
        환경설정 값에 지정한 첫번째 대기 서버가 보내는 응답을 확인 해서,
        대기 서버에서 WAL 레코드 복제를 완벽하게 했다고 운영 서버는 판단한다.
        여기서 언급한 환경설정 매개변수들이 대기 서버의 동기화 방식에 대한 
        설정에 관계된 것들이다.
        동기식 복제 기능 설정을 할 때는 어느 환경 변수는 대기 서버에서 설정하고, 
        어느 환경 변수는 운영 서버에서 설정하는지 잘 파악하고 있어야한다.
        또한, 대기 서버로 등록되는 서버들은 반드시 운영 서버와 직접 연결된 
        서버들이여야한다. 대기 서버의 하위 대기 서버는 동기식 복제를 사용할 수 없다.
   </para>

   <para>
    <varname>synchronous_commit</> 설정값을 <literal>remote_write</>로 하면, 
        대기 서버의 OS 차원에서 해당 자료가 디스크에 기록되었다는 것까지만 확인하다.
        실재로 OS가 디스크 버퍼 내용을 물리적으로 디스크에 기록했다는 것에 대해서는
        확인하지 않는다. 이 설정은 <literal>on</>으로 설정했을 때 보다는 
        자료를 안전하게 동기화 하지는 못한다. <productname>PostgreSQL</> 서버 장애가 
        아니라, OS 장애가 생겼을 경우에는 대기서버 측 자료 손실이 발생할 수도 
        있기 때문이다. 하지만, 동기화 작업 시간은 그 만큼 줄어들기 때문에, 
        특수 환경에서는 유용하게 사용될 수도 있다. 
        시스템 전체적인 입장에서 본다면, 자료가 손실 되는 경우는 
        운영서버와, 대기 서버 모두 동시에 장애가 발생될 경우에만 일어나기 때문에다. 
   </para>

   <para>
    동기식 복제 기능을 이용하는 경우 빠른 서버 중지 명령이 실행되면, 
        운영 서버가 정상적인 빠른 서버 중지 작업을 진행하지만, 
        비동기식 복제 기능을 이용하는 경우는
        대기 서버로 보내야할 WAL 레코드를 연결 되어 있는 모든 대기 서버로 모두 보내고
        서버가 중지된다.
   </para>

   </sect3>

   <sect3 id="synchronous-replication-performance">
    <title>성능을 고려한 계획</title>

   <para>
    동기식 복제 기능을 이용할 때는 세심한 계획이 필요하다.
        응용 프로그램들이 제 성능을 잘 낼 수 있도록 대기 서버들을 구축해야한다.
        대기 서버 작업 완료 확인을 위한 지연 작업이 시스템 자원을 거의 사용하지는 
        않지만, 그 만큼 트랜잭션의 잠금 현상이 일어난다. 결과적으로 
        세심한 계획 없이 무작정 구축한 동기식 복제 환경은 
        많은 클라이언트 접속이 있을 경우 심각하게 반응 시간이 느려지기도 한다.
   </para>

   <para>
    <productname>PostgreSQL</>에서는 
        응용 프로그램 개발자가 복제 작업에서의 
        커밋 트랜잭션 작업에 대한 운영 서버의 확인 수준을 결정할 수 있도록 
        제공한다. 이 수준 조정 작업은 시스템 전체를 대상으로 할 수도 있고, 
        사용자 단위, 데이터베이스 연결 세션 단위, 심지어 개별 트랜잭션 단위로도 
        할 수 있다.
   </para>

   <para>
    예를 들어 한 서비스에서 10% 정도는 고객의 중요한 세부 정보 변경 작업이고, 
        90%는 사용자가 채팅 정보와 같은 장애가 발생되어 자료 손실이 생겨도 치명적인 문제가 발생하지 않는 
        자료에 대한 작업으로 운영된다고 하자.
   </para>

   <para>
    이 때, 이 10% 작업에 대해서만 동기식 방식을 이용하고, 
        나머지는 비동기식으로 사용해서, 운영 서버의 성능을 개선할 수 있다.
        이것을 응용 프로그램측에서 지정해서, 특정 업무 상태에서만 
        동기식 복제를 이용할 수 있다.
   </para>

   <para>
    이와 함께 고려해야할 부분은 운영 서버와 대기 서버 사이 복제를 위해 
        사용되는 네트워크 사용량이다. 이 부분을 잘못 계산하면, 운영 서버가 운영을 위해
        사용해야할 네트워크 자원을 복제 작업 비용으로 써버리는 경우가 생기고, 
        이것은 곧바로 성능 저하를 발생시킨다.
   </para>

   </sect3>

   <sect3 id="synchronous-replication-ha">
    <title>고가용성을 고려한 계획</title>

   <para>
    운영 서버 환경 설정에서 <varname>synchronous_commit</> 값이 <literal>on</>
        또는 <literal>remote_write</>
        상태이면, 운영 서버에서 일어나는 모든 커밋은 
        대기 서버의 응답이 있을 때까지 대기하는 과정을 거치게 된다.
        운영 서버는 반드시 적어도 하나의 대기 서버에서는 커밋 완료 응답을 받아야 한다.
        그렇지 않으면, 운영 서버에서 일어나는 커밋은 무작정 기다리게 된다.
   </para>

   <para>
    자료 손실을 막는 가장 좋은 방법은 적어도 하나 이상의 동기식 대기 서버가 
        장애로 멈추지 않게 만드는 것이다.  운영 서버의 환경설정에서 
        <varname>synchronous_standby_names</> 변수의 값으로 동기시 방식을 이용할 
        대기 서버들을 나열해서 이것을 구현할 수 있다.  이 변수에 나열된(쉼표로 구분)
        첫번째 대기 서버가 응답이 없으면, 다음 대기 서버의 응답을 기다린다.
   </para>

   <para>
    대기 서버가 처음으로 실행되어 운영 서버로 접속하는 시점에는
        대기 서버는 아직까지는 운영 서버와 동기화가 되지 않았을 것이다.
        이 때, 대기 서버는 운영 서버 동기화를 위해, 더 이상 동기화를 할 필요가 없는 
        상태가 될 때까지 계속 <literal>스트리밍</> 방식으로 자료를 동기화 할 것이다.
        이런 일련의 상태를 <literal>따라잡기 catchup</> 상태라고 한다.
        이 상태의 기간은 대기 서버와 운영 서버의 자료 동기화 간격(차이가 나는 WAL 레코드 수)을 
        좁혀서, 최종적으로는 동기화 간격을 없게 만드는 시간이다.
        달리 말하면, 운영 서버에서는 반영되었으나, 대기 서버에는 아직 반영되지 않은 WAL 레코드들을
        모두 처리하는 시간이다.
        이 따라잡기 시간은 대기 서버가 얼마 동안 중지해 있었고, 
        그 사이 얼마나 많은 자료 변경 트랜잭션이 일어났냐에 따라 결정된다.
   </para>

   <para>
    운영 서버에서는 커밋되었고, 운영 서버가 대기 서버의 커밋 완료 응답을 
        기다리고 있는 중에 운영 서버가 재실행된다면, 
        운영 서버가 재실행 복구 작업 시, 그 트랜잭션은 대기 서버에서 
        커밋 완료 되었었다는 응답을 받았다고 간주하고, 복구 작업을 진행한다.
        이것은 모든 대기 서버가 그 커밋을 완료했는지 알길이 없기 때문이다. 
        하지만, 복구가 완료되어 운영서버가 정상적으로 실행되었고, 
        어떤 대기 서버는 그 작업을 아직 하지 않았다면, 
        그 작업부터 진행할 것이기 때문에, 자료 손실은 없을 것이다. 
        응용 프로그램 입장에서는 이런 상황이 발생했다면, 
        - 커밋 명령이 성공적으로 끝나기 전에 데이터베이스 연결이 끊겼다면 - 
        재연결시 반드시 해당 작업으로 자료가 정상적으로 
        반영되었는지 확인해야할 필요가 있다.
   </para>

   <para>
    <varname>synchronous_standby_names</> 환경 변수값에 등록된 모든 
        대기 서버들이 모두 커밋 완료 응답을 보내지 않아, 운영 서버의 커밋 작업이
        멈춰 있는 상태라면, 이 변수의 값을 빈문자열('')로 지정하고, 
        환경 설정을 다시 적용해서 운영 서버를 정상화 할 수 있다.
   </para>

   <para>
    운영 서버와 대기 서버와의 연결이 끊겼고, 대기 서버를 운영 서버로 사용해야할 
        상황이라면, 대기 서버들 가운데 운영 서버와 동기화가 잘 된 서버를 
        운영 서버로 선택하는 것은 관리자의 몫이다.
        (동기식 복제를 하는 대기 서버를 운영 서버로 채택하는 것이 제일 안전할 것이다.)
   </para>

   <para>
    대기 서버의 트랜잭션 완료 응답을 기다리고 있는 중에, 
        새로운 대기 서버를 만들어야할 상황이라면, 
        pg_start_backup(), pg_stop_backup() 함수를 사용해서, 
        일반 베이스 백업을 만드는 방식으로 만들면 되나, 
        이 때 이 작업을 하는 세션은 반드시, <varname>synchronous_commit</> = <literal>off</>
        환경으로 작업을 진행해야한다.
        그렇지 않으면, 윗 함수들 조차 대기 서버의 응답을 기다리게 되어 
        동기화 하고 있는 대기 서버의 문제가 풀릴 때까지 무한 대기 상태가 되어버린다.
   </para>

   </sect3>
  </sect2>
  </sect1>

  <sect1 id="warm-standby-failover">
   <title>장애처리 failover</title>

   <para>
    운영 중인 서버가 장애로 멈췄다면, 대기 중인 서버를 
        운영 서버로 사용할 장애처리 작업을 해야한다.
        이것을 failover 절체라고 한다. (절체라는 단어가 국어사전에 
        없는 단어라서 한자가 어떻게 되는지는 모르겠다.)
   </para>

   <para>
    대기 서버가 장애일 경우는 운영 서버에 영향을 주지 않기 때문에, 
        이 작업이 필요 없다.  그냥 재실행 할 수 있다면, 그렇게 하면 되고, 
        재구축이 필요하면, 대기 서버 구축 방법에 따라 진행하면 된다.
        대기 서버는 실행 순서에 따라 자동으로 운영 서버와 동기화를 할 것이다.
   </para>

   <para>
    장애처리 작업이 일어나서 새로운 운영 서버가 그 역할을 하기 시작했는데,
        장애가 생겼던 옛 운영 서버가 다시 실행되는 경우라면, 
        클라이언트가 그 옛 운영 서버를 사용할 수 없도록 조치할 필요가 있다.
        이것을 흔히 <acronym>STONITH</> (Shoot The Other Node In The Head)
        기능이라고 한다.
    두 개의 운영 서버가 실행 되고, 서로 자신이 운영 역할을 하기 때문에, 
        심각한 경우는 자료 손실이 일어난다. 이 문제를 어떻게 막을 것인지를 
        고려해야한다.
   </para>

   <para>
    많은 장애처리 기반 시스템은 두 개의 시스템으로 구성된다.
        이 시스템은 어떤 종류의 하트비트 메카니즘으로 주기적으로 
        장애처리를 해야하는지를 검사한다. 서로 하트비트 검사를 하는 방식 말고, 
        이 검사를 제 3의 서버(이것을 감시 서버라고 한다)를 맡아 
        보다 안전한 장애처리를 할 수 있도록 하기도 한다. 이 경우는 
        전자 방식보다 더 세밀한 테스트와 구축 비용이 더 많이 들것이다.
   </para>

   <para>
    <productname>PostgreSQL</productname>에서는 이 장애처리를 판단하고, 
        대기 서버에게 운영 서버 역할을 맡도록 알리는 시스템 프로그램을 
        제공하지는 않는다. 시스템 의존적인 작업이기 때문이기도 하고,
        이미 이런 소프트웨어는 많이 있다. 
   </para>

   <para>
    운영, 대기 각각 하나의 서버로 구성했을 경우, 
        대기 서버가 운영을 맡게 되면, 그 운영 서버에 대한 대기 서버가 없는 
        단독 운영 서버 환경이 되어버린다. 원래 구축 하려고 했던 가용성이 
        높은 시스템 환경 구축이라는 목표에서 벗어나게 됨을 의미한다.
        간단하게 생각하면, 멈추웠는 옛 운영 서버를 대기 서버로 사용하면 될 것이다고 
        하지만, 실무에서는 대기 서버가 어떤 문제로 운영을 맡게 될지 
        아무도 모르기 때문에, 이 생각은 위험하다. 
        만일 하드웨어 장애였다면, 그것을 고치고, 대기 서버로 새로 구축해서, 
        대기 서버로 실행해야하기 때문에, 꽤 많은 시간을 운영 서버 혼자 감당해야한다.
        운영적인 입장에서는 이런 경우 어떻게 최소한의 비용으로 빠르게 
        대기 서버를 구축할 것인가도 준비해야한다. 
        비용이 넉넉하다면, 제 3의 대기 서버를 준비해 두었다가, 
        이런 상황에서 대기 서버로 작동할 수 있도록 한다.
   </para>

   <para>
    결론적으로 장애처리 작업은 대기 서버가 운영 역할을 맡는 작업은 
        비교적 짧은 시간 안에 일어나지만, 다시 원래 환경과 같은 환경을 만드는 
        작업에는 꽤 많은 시간이 걸린다. 또한 대기 서버가 그 역할을 제대로 할 수 있는지 
        주기적으로 확인하는 작업도 필요하다. 확인 작업은 장애처리에 필요한 
        모든 작업이 될 것이다. 운영 서버 장애를 감지 할 수 있는지, 
        대기 서버는 잘 복제를 하고 있는지, 대기 서버가 운영 서버 역할을 맡고 
        별 이상이 없는지, 등등이 될 것이다.
   </para>

   <para>
    로그 전달 방식을 이용한 대기 서버환경이면, 
        이 대기 서버가 운영 서버 역할을 하게 하려면, 
        <command>pg_ctl promote</> 명령을 실행하거나, 
        <filename>recovery.conf</> 파일에 있는
        <varname>trigger_file</> 설정값으로 지정한 파일을 
        만들어주면 된다.
    <command>pg_ctl promote</> 명령을 사용할 경우에는 
        <varname>trigger_file</> 설정값이 지정되어 있지 않아도 된다.
    고가용성을 고려한 구축이 아니라, 
        그냥 읽기 전용 쿼리를 사용하기 위해서 구축한 로그 전달 방식의 
        대기 서버라면, 굳이 이 작업을 하지 않고, 그냥 
        운영 서버 장애를 직접 복구 하는 것이 나을 것이다.
   </para>
  </sect1>

  <sect1 id="log-shipping-alternative">
   <title>로그 전달 복제에 대한 다른 방법</title>

   <para>
    운영 서버에서 사용했던 로그를 대기 서버로 보내서 
        복제 기능을 구현하는 방법은
        <varname>restore_command</> 설정값으로 지정한 명령으로 
        전달 된 파일을 자기 서버에 적용하고, 
        적용할 파일이 없으면, 그 명령을 계속 반복하는 식이다.
        이 부분은 앞 장에서 구체적으로 설명했다. 
        여기서는 이 방법이 아닌, 8.4 이하 버전에서도 사용할 수 있는 
        데이터베이스 복구 기능을 이용해서 독자적인 
        로그 전달 복제 기법을 설명한다.
        이렇게 하려면, 대기 모드로 실행하지 않고, 
        단순 복구 모드로 실행하도록 <varname>standby_mode</> 설정값을
        off로 지정해야한다.
        <xref linkend="pgstandby"> 모듈이 이 독자적인 복제 기능을 
        구현해 놓은 것이다.
   </para>

   <para>
    이 방식에서 주의해야할 점은, 
        운영 서버에서 만들어진 WAL 파일은 그것들이 만들어지는 순서에 따라 
        그대로 대기 서버로 반영 되어야한다는 점이다. 또한 반영 하는 작업은 
        반드시 직렬화 되어서 한 번에 하나의 파일만 적용해야한다.
        대기 서버에서 쿼리를 사용할 수 있게 설정 한다면, (Hot Standby)
        WAL 파일 적용 간격에 차이 때문에, 자료가 정확하게 운영 서버와 같지 
        않다는 점도 기억해야한다. 
        이 대기 서버로의 자료 반영 지연 현상을 줄이려면, 
        <varname>archive_timeout</> 설정값을 짧게 하면 된다.
        또한 이 방식으로 구현하면, 스트리밍 방식 복제를 사용할 수 없다는 점도
        기억해야한다.
   </para>

   <para>
    기본 작동 방식은 일반적인 로그 전달, 복구 방식과 같다.
        트랜잭션 로그를 전달하는 방법은 WAL 레코드가 다 채워진, 
        WAL 세그먼트 파일을 서로 전달하고, 받아서 사용하는 길 뿐이다.
        운영 서버에서 만드는 순차적인 WAL 세그먼트 파일들이 
        대기 서버로 옮길 때, 누락되는 일이 없도록, 나중에 만들어진 파일이 
        이전에 만들어진 파일보다 먼저 대기 서버에 도착하는 일이 없도록
        해야한다. 또한 다른 운영 서버에서 만든 WAL 세그먼트 파일과 섞여 
        구분이 안되는 일이 없도록 해야한다.
        대기 기능만 구현하고자 한다면, WAL 파일 전달량은 그렇게 많지는 않다.
   </para>

   <para>
    복제 기능을 독자적으로 구현하는 열쇠는 <varname>restore_command</> 
        설정값에 있다. 이 값은 대기 서버가 실행할 때 사용하는 
        <filename>recovery.conf</> 파일안에 <varname>restore_command</>
        서버 환경 변수 매개변수 값으로 지정한다.
        여기서 사용하는 명령은 서버가 처리해야하는 파일이 없으면, 
        0 아닌 값을 리턴해서, 복구 모드를 종료하고, 
        일반적인 정상 운영 서버로 실행 되도록 한다. 
        하지만, 복제용 대기 서버로 구축하려면, 
        이 명령은 원하는 파일이 없으면, 그 파일이 생길 때까지(운영 서버가 
        대기 서버로 보내줄 때까지) 기다리고 있다가, 생기면 
        다시 대기 서버가 복구 작업을 계속 할 수 있어야한다.
        또한 <literal>.backup</>, <literal>.history</>이 운영 서버로부터 
        넘어 오면 그 파일은 무시하고, 0 아닌 값을 리턴하면서 이 명령을 끝내야한다.
        이렇게 설명한 모든 부분을 사용자가 직접 프로그래밍 해야한다.
        이 프로그램은 아울러, 장애처리를 위한 운영 역할로 전환할 수 있는 
        기능도 있어야하며, OS 시그널 처리도 있어야 한다.
   </para>

   <para>
    <varname>restore_command</> 설정값으로 사용될 프로그램의 의사코드는 다음과 같다:
<programlisting>
triggered = false;
while (!NextWALFileReady() &amp;&amp; !triggered)
{
    sleep(100000L);         /* wait for ~0.1 sec */
    if (CheckForExternalTrigger())
        triggered = true;
}
if (!triggered)
        CopyWALFileForRecovery();
</programlisting>
   </para>

   <para>
    이런 방식으로 구현된 실재 프로그램을 <xref linkend="pgstandby"> 모듈에서 
        제공한다.
        이 모듈은 위에서 설명한 구현 요소들을 모두 구현했다. 
        이 모듈과 함께 사용자 정의 스크립트들을 사용해서 구축할 수도 있을 것이다.
   </para>

   <para>
    어떻게 대기 서버가 운영 서버로 바뀔 것인가에 대한 설계는 
        꽤 중요한 부분이다. 이 또한 <varname>restore_command</> 설정값으로 지정하는 
        명령어에서 담당한다.
        단순하게 이 명령어의 리턴값이 0 아닌 값으로 종료되면 된다.
        0 아닌 값으로 종료되는 상황은 
        어떤 특정 파일이 생겼을 때, 또는 더 나아가 운영 서버가 응답이 없을 때, 
        등등 발생할 수 있는 모든 상황을 꼼꼼히 살펴보고 그것을 구현하면 된다.
        문제는 이 명령어 실행은 서버가 각 개별 WAL 파일에 대해서 
    한 번 처리하고, 종료되고, 다시 실행하는 식으로 작동되기 때문에, 
        서버 데몬과 달리 시그널 처리를 하기 힘들다. 그렇기 때문에, 
        어떤 특정 파일을 만들어 장애처리 신호로 사용하겠다면, 
        그 파일은 다른 프로세스가 만드는 것이 타당하다.
        한편, 운영 서버의  <varname>archive_timeout</> 값을 참조해서, 
        원하는 WAL 파일이 넘어오지 않을 경우 다음 작업을 할 수 있는 
        시간 제한 기능을 둘 수도 있으나, 이 때 네트워크 상태나, 운영 서버의 부하 상태도 함께 고려해야한다.
    그렇지 않으면, 의도 되지 않게 장애처리 기능이 작동해서, 
        상황을 더 악화시킬 수도 있다.
   </para>

  <sect2 id="warm-standby-config">
   <title>Implementation</title>

   <para>
    The short procedure for configuring a standby server using this alternative
    method is as follows. For
    full details of each step, refer to previous sections as noted.
    <orderedlist>
     <listitem>
      <para>
       Set up primary and standby systems as nearly identical as
       possible, including two identical copies of
       <productname>PostgreSQL</> at the same release level.
      </para>
     </listitem>
     <listitem>
      <para>
       Set up continuous archiving from the primary to a WAL archive
       directory on the standby server. Ensure that
       <xref linkend="guc-archive-mode">,
       <xref linkend="guc-archive-command"> and
       <xref linkend="guc-archive-timeout">
       are set appropriately on the primary
       (see <xref linkend="backup-archiving-wal">).
      </para>
     </listitem>
     <listitem>
      <para>
       Make a base backup of the primary server (see <xref
       linkend="backup-base-backup">), and load this data onto the standby.
      </para>
     </listitem>
     <listitem>
      <para>
       Begin recovery on the standby server from the local WAL
       archive, using a <filename>recovery.conf</> that specifies a
       <varname>restore_command</> that waits as described
       previously (see <xref linkend="backup-pitr-recovery">).
      </para>
     </listitem>
    </orderedlist>
   </para>

   <para>
    Recovery treats the WAL archive as read-only, so once a WAL file has
    been copied to the standby system it can be copied to tape at the same
    time as it is being read by the standby database server.
    Thus, running a standby server for high availability can be performed at
    the same time as files are stored for longer term disaster recovery
    purposes.
   </para>

   <para>
    For testing purposes, it is possible to run both primary and standby
    servers on the same system. This does not provide any worthwhile
    improvement in server robustness, nor would it be described as HA.
   </para>
  </sect2>

  <sect2 id="warm-standby-record">
   <title>Record-based Log Shipping</title>

   <para>
    It is also possible to implement record-based log shipping using this
    alternative method, though this requires custom development, and changes
    will still only become visible to hot standby queries after a full WAL
    file has been shipped.
   </para>

   <para>
    An external program can call the <function>pg_xlogfile_name_offset()</>
    function (see <xref linkend="functions-admin">)
    to find out the file name and the exact byte offset within it of
    the current end of WAL.  It can then access the WAL file directly
    and copy the data from the last known end of WAL through the current end
    over to the standby servers.  With this approach, the window for data
    loss is the polling cycle time of the copying program, which can be very
    small, and there is no wasted bandwidth from forcing partially-used
    segment files to be archived.  Note that the standby servers'
    <varname>restore_command</> scripts can only deal with whole WAL files,
    so the incrementally copied data is not ordinarily made available to
    the standby servers.  It is of use only when the primary dies &mdash;
    then the last partial WAL file is fed to the standby before allowing
    it to come up.  The correct implementation of this process requires
    cooperation of the <varname>restore_command</> script with the data
    copying program.
   </para>

   <para>
    Starting with <productname>PostgreSQL</> version 9.0, you can use
    streaming replication (see <xref linkend="streaming-replication">) to
    achieve the same benefits with less effort.
   </para>
  </sect2>
 </sect1>

 <sect1 id="hot-standby">
  <title>상시 대기</title>

  <indexterm zone="high-availability">
   <primary>Hot Standby</primary>
  </indexterm>
  <indexterm zone="high-availability">
   <primary>상시 대기</primary>
  </indexterm>


   <para>
    여기서 말하는 상시 대기 Hot Standby란 그 서버가 아카이브 파일로 
    복구 작업을 하고 있거나 대기 모드로 있을 때도 클라이언트가 
    그 서버로 접속할 수 있으며, 읽기 전용 쿼리를 실행할 수 있는 것을
    말한다.
    이 기능은 복제 기능을 구현하는 방법으로,
    가장 최근 상태로 백업을 하는 방법으로 유용하다.
    또한 상시 대기라는 용어는 
    그 대기 서버로 클라이언트들이 접속해 있는 상태에서 즉시, 
    운영 서버로 변경해서 운영 서버에서 사용하던 쿼리를 사용할 수 
    있는 기능을 뜻한다.
   </para>

   <para>
    상시 대기 모드에서 사용하는 쿼리도 크게 다르지는 않지만, 
    아래와 같이 몇가지 제약 사항이 있으며, 관리적인 측면에서 
    주의해야할 부분이 있다.
   </para>

  <sect2 id="hot-standby-users">
   <title>사용자 측면 개요</title>

   <para>
    When the <xref linkend="guc-hot-standby"> parameter is set to true on a
    standby server, it will begin accepting connections once the recovery has
    brought the system to a consistent state.  All such connections are
    strictly read-only; not even temporary tables may be written.
   </para>

   <para>
    The data on the standby takes some time to arrive from the primary server
    so there will be a measurable delay between primary and standby. Running the
    same query nearly simultaneously on both primary and standby might therefore
    return differing results. We say that data on the standby is
    <firstterm>eventually consistent</firstterm> with the primary.  Once the
    commit record for a transaction is replayed on the standby, the changes
    made by that transaction will be visible to any new snapshots taken on
    the standby.  Snapshots may be taken at the start of each query or at the
    start of each transaction, depending on the current transaction isolation
    level.  For more details, see <xref linkend="transaction-iso">.
   </para>

   <para>
    Transactions started during hot standby may issue the following commands:

    <itemizedlist>
     <listitem>
      <para>
       Query access - <command>SELECT</>, <command>COPY TO</>
      </para>
     </listitem>
     <listitem>
      <para>
       Cursor commands - <command>DECLARE</>, <command>FETCH</>, <command>CLOSE</>
      </para>
     </listitem>
     <listitem>
      <para>
       Parameters - <command>SHOW</>, <command>SET</>, <command>RESET</>
      </para>
     </listitem>
     <listitem>
      <para>
       Transaction management commands
        <itemizedlist>
         <listitem>
          <para>
           <command>BEGIN</>, <command>END</>, <command>ABORT</>, <command>START TRANSACTION</>
          </para>
         </listitem>
         <listitem>
          <para>
           <command>SAVEPOINT</>, <command>RELEASE</>, <command>ROLLBACK TO SAVEPOINT</>
          </para>
         </listitem>
         <listitem>
          <para>
           <command>EXCEPTION</> blocks and other internal subtransactions
          </para>
         </listitem>
        </itemizedlist>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>LOCK TABLE</>, though only when explicitly in one of these modes:
       <literal>ACCESS SHARE</>, <literal>ROW SHARE</> or <literal>ROW EXCLUSIVE</>.
      </para>
     </listitem>
     <listitem>
      <para>
       Plans and resources - <command>PREPARE</>, <command>EXECUTE</>,
       <command>DEALLOCATE</>, <command>DISCARD</>
      </para>
     </listitem>
     <listitem>
      <para>
       Plugins and extensions - <command>LOAD</>
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
    Transactions started during hot standby will never be assigned a
    transaction ID and cannot write to the system write-ahead log.
    Therefore, the following actions will produce error messages:

    <itemizedlist>
     <listitem>
      <para>
       Data Manipulation Language (DML) - <command>INSERT</>,
       <command>UPDATE</>, <command>DELETE</>, <command>COPY FROM</>,
       <command>TRUNCATE</>.
       Note that there are no allowed actions that result in a trigger
       being executed during recovery.  This restriction applies even to
       temporary tables, because table rows cannot be read or written without
       assigning a transaction ID, which is currently not possible in a
       Hot Standby environment.
      </para>
     </listitem>
     <listitem>
      <para>
       Data Definition Language (DDL) - <command>CREATE</>,
       <command>DROP</>, <command>ALTER</>, <command>COMMENT</>.
       This restriction applies even to temporary tables, because carrying
       out these operations would require updating the system catalog tables.
      </para>
     </listitem>
     <listitem>
      <para>
       <command>SELECT ... FOR SHARE | UPDATE</>, because row locks cannot be
       taken without updating the underlying data files.
      </para>
     </listitem>
     <listitem>
      <para>
       Rules on <command>SELECT</> statements that generate DML commands.
      </para>
     </listitem>
     <listitem>
      <para>
       <command>LOCK</> that explicitly requests a mode higher than <literal>ROW EXCLUSIVE MODE</>.
      </para>
     </listitem>
     <listitem>
      <para>
       <command>LOCK</> in short default form, since it requests <literal>ACCESS EXCLUSIVE MODE</>.
      </para>
     </listitem>
     <listitem>
      <para>
       Transaction management commands that explicitly set non-read-only state:
        <itemizedlist>
         <listitem>
          <para>
            <command>BEGIN READ WRITE</>,
            <command>START TRANSACTION READ WRITE</>
          </para>
         </listitem>
         <listitem>
          <para>
            <command>SET TRANSACTION READ WRITE</>,
            <command>SET SESSION CHARACTERISTICS AS TRANSACTION READ WRITE</>
          </para>
         </listitem>
         <listitem>
          <para>
           <command>SET transaction_read_only = off</>
          </para>
         </listitem>
        </itemizedlist>
      </para>
     </listitem>
     <listitem>
      <para>
       Two-phase commit commands - <command>PREPARE TRANSACTION</>,
       <command>COMMIT PREPARED</>, <command>ROLLBACK PREPARED</>
       because even read-only transactions need to write WAL in the
       prepare phase (the first phase of two phase commit).
      </para>
     </listitem>
     <listitem>
      <para>
       Sequence updates - <function>nextval()</>, <function>setval()</>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>LISTEN</>, <command>UNLISTEN</>, <command>NOTIFY</>
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
    In normal operation, <quote>read-only</> transactions are allowed to
    update sequences and to use <command>LISTEN</>, <command>UNLISTEN</>, and
    <command>NOTIFY</>, so Hot Standby sessions operate under slightly tighter
    restrictions than ordinary read-only sessions.  It is possible that some
    of these restrictions might be loosened in a future release.
   </para>

   <para>
    During hot standby, the parameter <varname>transaction_read_only</> is always
    true and may not be changed.  But as long as no attempt is made to modify
    the database, connections during hot standby will act much like any other
    database connection.  If failover or switchover occurs, the database will
    switch to normal processing mode.  Sessions will remain connected while the
    server changes mode.  Once hot standby finishes, it will be possible to
    initiate read-write transactions (even from a session begun during
    hot standby).
   </para>

   <para>
    Users will be able to tell whether their session is read-only by
    issuing <command>SHOW transaction_read_only</>.  In addition, a set of
    functions (<xref linkend="functions-recovery-info-table">) allow users to
    access information about the standby server. These allow you to write
    programs that are aware of the current state of the database. These
    can be used to monitor the progress of recovery, or to allow you to
    write complex programs that restore the database to particular states.
   </para>
  </sect2>

  <sect2 id="hot-standby-conflict">
   <title>쿼리 충돌 처리하기</title>

   <para>
    운영 서버와 대기 서버은 대부분 느슨한 연결 상태를 유지한다. 운영 서버에서 
    발생하는 트랜잭션 커밋은 대기서버가 그 트랜잭션을 정상적으로 커밋 
    했는지와 상관 없이 정상 처리된다.  이런 특성 때문에, 이런 복제 기법에는
    항상 예상치 않은 장애와 두 서버간 자료 충돌이 발생할 가능성을 내포하고
    있다.  가장 대표적인 자료 충돌로는 성능 저하가 발생하는 것을 꼽을 수 있을
    것이다:  예를 들어 운영 서버에서 많은 자료가 입력되고 있다면, 그로 인해
    많은 트랜잭션 로그가 만들어 질 것이고, 이것을 대기서버로 전달하기 위해
    운영 서버는 단일 서버를 운영 할 때와 달리 부가적인 입출력 자원을 
    사용할 것이다.  또한 대기 서버에서도 실행 되고 있던 쿼리들이 이 입력 처리 
    때문에 발생하는 비용 때문에 영향을 받을 것이다.
   </para>

   <para>
    다음은 대기 서버에서 발생할 수 있는 자료 충돌 종류들이다.
    이런 충돌을 해결 하기 위해서는 어떤 경우는 실행 되고 있는 쿼리를 
    중지 하는 경우도 있고, 또는 세션을 중지해야 하는 경우도 발생할 것이다. 
    이런 의미에서 이런 충돌은 <emphasis>강한 충돌</>이라고 한다.
    사용자는 이런 충돌을 잘 이해해서 각 상황에 맞는 조치를 취해야 한다:

      <itemizedlist>
       <listitem>
        <para>
         운영 서버에서 <command>LOCK</> 명령을 사용했거나, 
         다양한 <acronym>DDL</> 구문에 의해서 발생하는 
         배타적 접근 잠금 Access Exclusive Lock 에 대해서, 
         대기 서버는 그것에 대한 정확한 상태를 유지하지 못한다. 즉, 
         운영 서버에서 해당 객체가 잠겨도 대기 서버에서는 접근이 가능하다.
         (이렇게 되면, 대기 서버에서 읽어서 운영 서버로 반영하는 자료들이
         그 정합성을 잃을 수 있다. - 옮긴이)
        </para>
       </listitem>
       <listitem>
        <para>
         운영 서버에서 테이블 스페이스가 삭제 되고 있는 중에도 대기 서버는
         그 테이블 스페이스에 속한 객체들을 접근할 수 있다.
        </para>
       </listitem>
       <listitem>
        <para>
         대기 서버에 해당 데이터베이스를 사용하는 세션이 있음에도 불구하고, 
         운영 서버에서 해당 데이터베이스를 삭제 할 수 있다.
        </para>
       </listitem>
       <listitem>
        <para>
         대기 서버에서 발생한 트랜잭션을 위해 보관 되어야 할 
         옛 버전 자료들이 운영 서버의 vacuum 작업으로 삭제 되어 버리는 
         일이 생길 수 있다.
        </para>
       </listitem>
       <listitem>
        <para>
         위 경우와 반대로 보이지 말아야 할 옛 버전 자료들이 
         보여지는 경우도 발생할 수 있다.
        </para>
       </listitem>
      </itemizedlist>
   </para>

   <para>
    단독으로 운영 되는 서버라면, 이런 쿼리 충돌이 일어나지 않는다. 왜냐하면, 
    한 작업이 마무리 되기 전까지 그 작업과 관련된 다른 세션들의 작업들은 
    대기 상태가 되기 때문이다. 하지만 복제 환경에서 대기 서버는 이런 
    대기를 제어 할 수 없다: 운영 서버에서 발생한 트랜잭션 로그를 
    대기 서버가 반영 하도록 전해 받았다면, 그저 그 작업을 진행할 뿐이기 
    때문이다. 이 작업을 진행 할 때, 운영 서버의 다른 세션 상태를 고려할 수 
    없기 때문이다. 물론 가장 완벽한 방법은 대기 서버까지도 모두 해당 트랜잭션 작업이 끝날 때까지 모든 세션(운영 서버의 세션과 대기 서버의 세션 모두)의 대기 상태를 유지 하는 것이지만, 현실적으로 대기 서버와 운영 서버간의 연결을 완벽하게 보장한다는 것은 거의 불가능하기 때문에, 이런 방식은 오히려 운영 서버의 안정성을 더 떨어뜨린다. 그래서, 이런 충돌이 발생했을 때 대기 서버는 충돌을 해결 하기 위한 별도의 처리 방식을 제공하고 있어야 하며, 이에 따라 몇가지 충돌 자동 해결 기능을 제공하고 있다.
   </para>

   <para>
    그 한 예로 운영 서버에서 <command>DROP TABLE</> 명령으로 한 테이블을
    삭제 한다면, 대기 서버에서 아직 삭제 되지 않은 그 테이블을 조회하는 쿼리는
    운영 서버에서 전달 받은 이 트랜잭션이 감지 되면 자동으로 취소 된다.
    일반적으로 단독 서버 환경이면, 조회 작업이 먼저 진행 중이고, 
    삭제 작업이 발생 했다면, 조회 작업이 끝날 동안 삭제 작업은 기다린다.
    하지만 대기 서버가 있는 상황에서는 운영 서버가 대기 서버에서 해당 
    테이블을 조회하는 작업이 있는지 알 수 없음으로 일단 삭제하고, 
    그 로그를 대기 서버로 보낸다.  이때 대기 서버의 가장 바람직한 선택은
    대기 서버에서 조회 하고 있던 쿼리를 자동으로 취소하고, 최대한 빨리
    운영 서버에서 실행 했던 삭제 작업을 대기 서버에도 반영 하는 것이다.
    이렇게 처리하지 않고 운영 서버처럼 조회 작업이 끝날 때까지 기다렸다가 
    삭제 작업을 진행한다면, 오히려 자료 동기화 (복제 작업) 의 근본 목적을
    달성하는데 방해가 될 것이다.
   </para>

   <para>
    달리 생각하면, 해당 충돌이 순십간에 끝나는 경우라면, 충돌을 피하기 위해
    그냥 대기서버도 운영 서버 방식을 취하는 것이 바람직할 것이다.  하지만, 
    대기 서버의 조회 작업이 오래 지속된다면, 트랜잭션 로그 동기화는 그만큼 
    지연 될 것이고, 이에 따른 다른 객체들까지 영향을 받을 것이다. 
    그래서, <xref linkend="guc-max-standby-archive-delay">, <xref
    linkend="guc-max-standby-streaming-delay"> 환경 설정 매개변수로
    이런 최대 지연 시간을 지정해서 이 지연 시간을 넘으면 대기 서버의 작업을 
    중지 하도록 설정 한다.  이렇게 함으로 최대한 대기 서버의 상태를 
    운영 서버와 같도록 한다. 이 두 환경 설정 매개변수는 아카이브 로그 파일 
    반영에서, 스트리밍 트랜잭션 로그 전달에서 최대 지연 시간을 지정하는 것이다.
    (이 설정값들의 초기값은 30초다.  이 값의 최적값을 찾는 것은 데이터베이스
    관리자의 몫인 것 같다.  - 옮긴이)
   </para>

   <para>
    In a standby server that exists primarily for high availability, it's
    best to set the delay parameters relatively short, so that the server
    cannot fall far behind the primary due to delays caused by standby
    queries.  However, if the standby server is meant for executing
    long-running queries, then a high or even infinite delay value may be
    preferable.  Keep in mind however that a long-running query could
    cause other sessions on the standby server to not see recent changes
    on the primary, if it delays application of WAL records.
   </para>

   <para>
    Once the delay specified by <varname>max_standby_archive_delay</> or
    <varname>max_standby_streaming_delay</> has been exceeded, conflicting
    queries will be canceled.  This usually results just in a cancellation
    error, although in the case of replaying a <command>DROP DATABASE</>
    the entire conflicting session will be terminated.  Also, if the conflict
    is over a lock held by an idle transaction, the conflicting session is
    terminated (this behavior might change in the future).
   </para>

   <para>
    Canceled queries may be retried immediately (after beginning a new
    transaction, of course).  Since query cancellation depends on
    the nature of the WAL records being replayed, a query that was
    canceled may well succeed if it is executed again.
   </para>

   <para>
    Keep in mind that the delay parameters are compared to the elapsed time
    since the WAL data was received by the standby server.  Thus, the grace
    period allowed to any one query on the standby is never more than the
    delay parameter, and could be considerably less if the standby has already
    fallen behind as a result of waiting for previous queries to complete, or
    as a result of being unable to keep up with a heavy update load.
   </para>

   <para>
    The most common reason for conflict between standby queries and WAL replay
    is <quote>early cleanup</>.  Normally, <productname>PostgreSQL</> allows
    cleanup of old row versions when there are no transactions that need to
    see them to ensure correct visibility of data according to MVCC rules.
    However, this rule can only be applied for transactions executing on the
    master.  So it is possible that cleanup on the master will remove row
    versions that are still visible to a transaction on the standby.
   </para>

   <para>
    Experienced users should note that both row version cleanup and row version
    freezing will potentially conflict with standby queries. Running a manual
    <command>VACUUM FREEZE</> is likely to cause conflicts even on tables with
    no updated or deleted rows.
   </para>

   <para>
    Users should be clear that tables that are regularly and heavily updated
    on the primary server will quickly cause cancellation of longer running
    queries on the standby. In such cases the setting of a finite value for
    <varname>max_standby_archive_delay</> or
    <varname>max_standby_streaming_delay</> can be considered similar to
    setting <varname>statement_timeout</>.
   </para>

   <para>
    Remedial possibilities exist if the number of standby-query cancellations
    is found to be unacceptable.  The first option is to set the parameter
    <varname>hot_standby_feedback</>, which prevents <command>VACUUM</> from
    removing recently-dead rows and so cleanup conflicts do not occur.
    If you do this, you
    should note that this will delay cleanup of dead rows on the primary,
    which may result in undesirable table bloat. However, the cleanup
    situation will be no worse than if the standby queries were running
    directly on the primary server, and you are still getting the benefit of
    off-loading execution onto the standby.
    <varname>max_standby_archive_delay</> must be kept large in this case,
    because delayed WAL files might already contain entries that conflict with
    the desired standby queries.
   </para>

   <para>
    Another option is to increase <xref linkend="guc-vacuum-defer-cleanup-age">
    on the primary server, so that dead rows will not be cleaned up as quickly
    as they normally would be.  This will allow more time for queries to
    execute before they are canceled on the standby, without having to set
    a high <varname>max_standby_streaming_delay</>.  However it is
    difficult to guarantee any specific execution-time window with this
    approach, since <varname>vacuum_defer_cleanup_age</> is measured in
    transactions executed on the primary server.
   </para>

   <para>
    The number of query cancels and the reason for them can be viewed using
    the <structname>pg_stat_database_conflicts</> system view on the standby
    server. The <structname>pg_stat_database</> system view also contains
    summary information.
   </para>
  </sect2>

  <sect2 id="hot-standby-admin">
   <title>관리자 측면 개요</title>

   <para>
    If <varname>hot_standby</> is turned <literal>on</> in
    <filename>postgresql.conf</> and there is a <filename>recovery.conf</>
    file present, the server will run in Hot Standby mode.
    However, it may take some time for Hot Standby connections to be allowed,
    because the server will not accept connections until it has completed
    sufficient recovery to provide a consistent state against which queries
    can run.  During this period,
    clients that attempt to connect will be refused with an error message.
    To confirm the server has come up, either loop trying to connect from
    the application, or look for these messages in the server logs:

<programlisting>
LOG:  entering standby mode

... then some time later ...

LOG:  consistent recovery state reached
LOG:  database system is ready to accept read only connections
</programlisting>

    Consistency information is recorded once per checkpoint on the primary.
    It is not possible to enable hot standby when reading WAL
    written during a period when <varname>wal_level</> was not set to
    <literal>hot_standby</> on the primary.  Reaching a consistent state can
    also be delayed in the presence of both of these conditions:

      <itemizedlist>
       <listitem>
        <para>
         A write transaction has more than 64 subtransactions
        </para>
       </listitem>
       <listitem>
        <para>
         Very long-lived write transactions
        </para>
       </listitem>
      </itemizedlist>

    If you are running file-based log shipping ("warm standby"), you might need
    to wait until the next WAL file arrives, which could be as long as the
    <varname>archive_timeout</> setting on the primary.
   </para>

   <para>
    The setting of some parameters on the standby will need reconfiguration
    if they have been changed on the primary. For these parameters,
    the value on the standby must
    be equal to or greater than the value on the primary. If these parameters
    are not set high enough then the standby will refuse to start.
    Higher values can then be supplied and the server
    restarted to begin recovery again.  These parameters are:

      <itemizedlist>
       <listitem>
        <para>
         <varname>max_connections</>
        </para>
       </listitem>
       <listitem>
        <para>
         <varname>max_prepared_transactions</>
        </para>
       </listitem>
       <listitem>
        <para>
         <varname>max_locks_per_transaction</>
        </para>
       </listitem>
      </itemizedlist>
   </para>

   <para>
    It is important that the administrator select appropriate settings for
    <xref linkend="guc-max-standby-archive-delay"> and <xref
    linkend="guc-max-standby-streaming-delay">.  The best choices vary
    depending on business priorities.  For example if the server is primarily
    tasked as a High Availability server, then you will want low delay
    settings, perhaps even zero, though that is a very aggressive setting. If
    the standby server is tasked as an additional server for decision support
    queries then it might be acceptable to set the maximum delay values to
    many hours, or even -1 which means wait forever for queries to complete.
   </para>

   <para>
    Transaction status "hint bits" written on the primary are not WAL-logged,
    so data on the standby will likely re-write the hints again on the standby.
    Thus, the standby server will still perform disk writes even though
    all users are read-only; no changes occur to the data values
    themselves.  Users will still write large sort temporary files and
    re-generate relcache info files, so no part of the database
    is truly read-only during hot standby mode.
    Note also that writes to remote databases using
    <application>dblink</application> module, and other operations outside the
    database using PL functions will still be possible, even though the
    transaction is read-only locally.
   </para>

   <para>
    The following types of administration commands are not accepted
    during recovery mode:

      <itemizedlist>
       <listitem>
        <para>
         Data Definition Language (DDL) - e.g. <command>CREATE INDEX</>
        </para>
       </listitem>
       <listitem>
        <para>
         Privilege and Ownership - <command>GRANT</>, <command>REVOKE</>,
         <command>REASSIGN</>
        </para>
       </listitem>
       <listitem>
        <para>
         Maintenance commands - <command>ANALYZE</>, <command>VACUUM</>,
         <command>CLUSTER</>, <command>REINDEX</>
        </para>
       </listitem>
      </itemizedlist>
   </para>

   <para>
    Again, note that some of these commands are actually allowed during
    "read only" mode transactions on the primary.
   </para>

   <para>
    As a result, you cannot create additional indexes that exist solely
    on the standby, nor statistics that exist solely on the standby.
    If these administration commands are needed, they should be executed
    on the primary, and eventually those changes will propagate to the
    standby.
   </para>

   <para>
    <function>pg_cancel_backend()</>
        and <function>pg_terminate_backend()</> will work on user backends,
        but not the Startup process, which performs
        recovery. <structname>pg_stat_activity</structname> does not show an
        entry for the Startup process, nor do recovering transactions show
        as active. As a result, <structname>pg_prepared_xacts</structname>
        is always empty during recovery. If you wish to resolve in-doubt
        prepared transactions, view <literal>pg_prepared_xacts</> on the
        primary and issue commands to resolve transactions there.
   </para>

   <para>
    <structname>pg_locks</structname> will show locks held by backends,
    as normal. <structname>pg_locks</structname> also shows
    a virtual transaction managed by the Startup process that owns all
    <literal>AccessExclusiveLocks</> held by transactions being replayed by recovery.
    Note that the Startup process does not acquire locks to
    make database changes, and thus locks other than <literal>AccessExclusiveLocks</>
    do not show in <structname>pg_locks</structname> for the Startup
    process; they are just presumed to exist.
   </para>

   <para>
    The <productname>Nagios</> plugin <productname>check_pgsql</> will
    work, because the simple information it checks for exists.
    The <productname>check_postgres</> monitoring script will also work,
    though some reported values could give different or confusing results.
    For example, last vacuum time will not be maintained, since no
    vacuum occurs on the standby.  Vacuums running on the primary
    do still send their changes to the standby.
   </para>

   <para>
    WAL file control commands will not work during recovery,
    e.g. <function>pg_start_backup</>, <function>pg_switch_xlog</> etc.
   </para>

   <para>
    Dynamically loadable modules work, including <structname>pg_stat_statements</>.
   </para>

   <para>
    Advisory locks work normally in recovery, including deadlock detection.
    Note that advisory locks are never WAL logged, so it is impossible for
    an advisory lock on either the primary or the standby to conflict with WAL
    replay. Nor is it possible to acquire an advisory lock on the primary
    and have it initiate a similar advisory lock on the standby. Advisory
    locks relate only to the server on which they are acquired.
   </para>

   <para>
    Trigger-based replication systems such as <productname>Slony</>,
    <productname>Londiste</> and <productname>Bucardo</> won't run on the
    standby at all, though they will run happily on the primary server as
    long as the changes are not sent to standby servers to be applied.
    WAL replay is not trigger-based so you cannot relay from the
    standby to any system that requires additional database writes or
    relies on the use of triggers.
   </para>

   <para>
    New OIDs cannot be assigned, though some <acronym>UUID</> generators may still
    work as long as they do not rely on writing new status to the database.
   </para>

   <para>
    Currently, temporary table creation is not allowed during read only
    transactions, so in some cases existing scripts will not run correctly.
    This restriction might be relaxed in a later release. This is
    both a SQL Standard compliance issue and a technical issue.
   </para>

   <para>
    <command>DROP TABLESPACE</> can only succeed if the tablespace is empty.
    Some standby users may be actively using the tablespace via their
    <varname>temp_tablespaces</> parameter. If there are temporary files in the
    tablespace, all active queries are canceled to ensure that temporary
    files are removed, so the tablespace can be removed and WAL replay
    can continue.
   </para>

   <para>
    Running <command>DROP DATABASE</> or <command>ALTER DATABASE ... SET
    TABLESPACE</> on the primary
    will generate a WAL entry that will cause all users connected to that
    database on the standby to be forcibly disconnected. This action occurs
    immediately, whatever the setting of
    <varname>max_standby_streaming_delay</>. Note that
    <command>ALTER DATABASE ... RENAME</> does not disconnect users, which
    in most cases will go unnoticed, though might in some cases cause a
    program confusion if it depends in some way upon database name.
   </para>

   <para>
    In normal (non-recovery) mode, if you issue <command>DROP USER</> or <command>DROP ROLE</>
    for a role with login capability while that user is still connected then
    nothing happens to the connected user - they remain connected. The user cannot
    reconnect however. This behavior applies in recovery also, so a
    <command>DROP USER</> on the primary does not disconnect that user on the standby.
   </para>

   <para>
    The statistics collector is active during recovery. All scans, reads, blocks,
    index usage, etc., will be recorded normally on the standby. Replayed
    actions will not duplicate their effects on primary, so replaying an
    insert will not increment the Inserts column of pg_stat_user_tables.
    The stats file is deleted at the start of recovery, so stats from primary
    and standby will differ; this is considered a feature, not a bug.
   </para>

   <para>
    Autovacuum is not active during recovery.  It will start normally at the
    end of recovery.
   </para>

   <para>
    The background writer is active during recovery and will perform
    restartpoints (similar to checkpoints on the primary) and normal block
    cleaning activities. This can include updates of the hint bit
    information stored on the standby server.
    The <command>CHECKPOINT</> command is accepted during recovery,
    though it performs a restartpoint rather than a new checkpoint.
   </para>
  </sect2>

  <sect2 id="hot-standby-parameters">
   <title>상시 대기 관련 환경 설정 매개변수 설명</title>

   <para>
    Various parameters have been mentioned above in
    <xref linkend="hot-standby-conflict"> and
    <xref linkend="hot-standby-admin">.
   </para>

   <para>
    On the primary, parameters <xref linkend="guc-wal-level"> and
    <xref linkend="guc-vacuum-defer-cleanup-age"> can be used.
    <xref linkend="guc-max-standby-archive-delay"> and
    <xref linkend="guc-max-standby-streaming-delay"> have no effect if set on
    the primary.
   </para>

   <para>
    On the standby, parameters <xref linkend="guc-hot-standby">,
    <xref linkend="guc-max-standby-archive-delay"> and
    <xref linkend="guc-max-standby-streaming-delay"> can be used.
    <xref linkend="guc-vacuum-defer-cleanup-age"> has no effect
    as long as the server remains in standby mode, though it will
    become relevant if the standby becomes primary.
   </para>
  </sect2>

  <sect2 id="hot-standby-caveats">
   <title>주의사항</title>

   <para>
    There are several limitations of Hot Standby.
    These can and probably will be fixed in future releases:

  <itemizedlist>
   <listitem>
    <para>
     Operations on hash indexes are not presently WAL-logged, so
     replay will not update these indexes.
    </para>
   </listitem>
   <listitem>
    <para>
     Full knowledge of running transactions is required before snapshots
     can be taken. Transactions that use large numbers of subtransactions
     (currently greater than 64) will delay the start of read only
     connections until the completion of the longest running write transaction.
     If this situation occurs, explanatory messages will be sent to the server log.
    </para>
   </listitem>
   <listitem>
    <para>
     Valid starting points for standby queries are generated at each
     checkpoint on the master. If the standby is shut down while the master
     is in a shutdown state, it might not be possible to re-enter Hot Standby
     until the primary is started up, so that it generates further starting
     points in the WAL logs.  This situation isn't a problem in the most
     common situations where it might happen. Generally, if the primary is
     shut down and not available anymore, that's likely due to a serious
     failure that requires the standby being converted to operate as
     the new primary anyway.  And in situations where the primary is
     being intentionally taken down, coordinating to make sure the standby
     becomes the new primary smoothly is also standard procedure.
    </para>
   </listitem>
   <listitem>
    <para>
     At the end of recovery, <literal>AccessExclusiveLocks</> held by prepared transactions
     will require twice the normal number of lock table entries. If you plan
     on running either a large number of concurrent prepared transactions
     that normally take <literal>AccessExclusiveLocks</>, or you plan on having one
     large transaction that takes many <literal>AccessExclusiveLocks</>, you are
     advised to select a larger value of <varname>max_locks_per_transaction</>,
     perhaps as much as twice the value of the parameter on
     the primary server. You need not consider this at all if
     your setting of <varname>max_prepared_transactions</> is 0.
    </para>
   </listitem>
   <listitem>
    <para>
     The Serializable transaction isolation level is not yet available in hot
     standby.  (See <xref linkend="xact-serializable"> and
     <xref linkend="serializable-consistency"> for details.)
     An attempt to set a transaction to the serializable isolation level in
     hot standby mode will generate an error.
    </para>
   </listitem>
  </itemizedlist>

   </para>
  </sect2>

 </sect1>

</chapter>
